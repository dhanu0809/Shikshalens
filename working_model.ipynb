{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanu0809/Shikshalens/blob/main/working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by reading the Excel file with pandas"
      ],
      "metadata": {
        "id": "T5USnZMJevbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Qk1EMfcIIB",
        "outputId": "cdc64a1f-3eaf-4476-eb14-a21dce2cbbea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Student ID        Student Name Student ID.1  Attendance (%)  Internal Marks  \\\n",
            "0       S001       Himmat Sehgal         S001           56.22              16   \n",
            "1       S002      Reyansh Tailor         S002           96.55              26   \n",
            "2       S003           Tanya Ben         S003           81.24              29   \n",
            "3       S004        Yasmin Reddy         S004           71.91              38   \n",
            "4       S005  Dharmajan Dhaliwal         S005           40.92              13   \n",
            "\n",
            "   External Marks  Total Marks Grade  Gender  Age  ... Toilet Facilities  \\\n",
            "0              51           67     B    Male   12  ...               Yes   \n",
            "1              25           51     C  Female   11  ...               Yes   \n",
            "2              51           80     B    Male   12  ...               Yes   \n",
            "3              23           61     B  Female   11  ...               Yes   \n",
            "4              30           43     C  Female   10  ...               Yes   \n",
            "\n",
            "  Library Guardian Contact Preferred Mode           Father Name  \\\n",
            "0     Yes       9014475712       WhatsApp          Akarsh Borra   \n",
            "1      No       9592551615            SMS             Baiju Din   \n",
            "2      No       9021637593            SMS            Rania Seth   \n",
            "3      No       9486986073            SMS    Pranay Subramanian   \n",
            "4      No       9262754377            SMS  Uthkarsh Chakraborty   \n",
            "\n",
            "        Mother Name    Class  Section  Class-Section             Teacher  \n",
            "0        Renee Sood  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "1      Advik Mammen  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "2  Vaibhav Bhargava  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "3          Sara Rau  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "4     Nirvi Shankar  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 33 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Student ID                500 non-null    object \n",
            " 1   Student Name              500 non-null    object \n",
            " 2   Student ID.1              500 non-null    object \n",
            " 3   Attendance (%)            500 non-null    float64\n",
            " 4   Internal Marks            500 non-null    int64  \n",
            " 5   External Marks            500 non-null    int64  \n",
            " 6   Total Marks               500 non-null    int64  \n",
            " 7   Grade                     500 non-null    object \n",
            " 8   Gender                    500 non-null    object \n",
            " 9   Age                       500 non-null    int64  \n",
            " 10  Religion/Caste            500 non-null    object \n",
            " 11  BPL Status                500 non-null    object \n",
            " 12  Parent Education Level    317 non-null    object \n",
            " 13  Family Income Range       500 non-null    object \n",
            " 14  DIKSHA Access             500 non-null    object \n",
            " 15  Digital Learning Hours    500 non-null    int64  \n",
            " 16  Participation in Quiz     500 non-null    object \n",
            " 17  Homework Submission Rate  500 non-null    float64\n",
            " 18  Disciplinary Records      500 non-null    int64  \n",
            " 19  School Name               500 non-null    object \n",
            " 20  District                  500 non-null    object \n",
            " 21  Student-Teacher Ratio     500 non-null    int64  \n",
            " 22  Electricity               500 non-null    object \n",
            " 23  Toilet Facilities         500 non-null    object \n",
            " 24  Library                   500 non-null    object \n",
            " 25  Guardian Contact          500 non-null    int64  \n",
            " 26  Preferred Mode            500 non-null    object \n",
            " 27  Father Name               500 non-null    object \n",
            " 28  Mother Name               500 non-null    object \n",
            " 29  Class                     500 non-null    object \n",
            " 30  Section                   500 non-null    object \n",
            " 31  Class-Section             500 non-null    object \n",
            " 32  Teacher                   500 non-null    object \n",
            "dtypes: float64(2), int64(8), object(23)\n",
            "memory usage: 129.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the Excel data (adjust the filename/path as needed)\n",
        "df = pd.read_excel(\"student_dt_classwise_indian_teachers (1).xlsx\")\n",
        "\n",
        "# Take a look at the first few rows and summary information\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset includes columns such as student names, IDs, and other non-predictive features, remove columns that are not useful for prediction. Also, check for missing values, clean data, and fix any inconsistencies.\n"
      ],
      "metadata": {
        "id": "wYMAj4XMe05x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "D2hWg-0Zog7_",
        "outputId": "fdec7388-0093-4b2d-c790-ebea5fb13bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Attendance (%)  Internal Marks  External Marks  Total Marks  \\\n",
              "count      500.000000      500.000000      500.000000   500.000000   \n",
              "mean        72.629400       24.912000       40.770000    65.682000   \n",
              "std         17.082218        9.072203       12.046382    15.117074   \n",
              "min         30.390000       10.000000       20.000000    30.000000   \n",
              "25%         62.457500       16.750000       30.000000    55.000000   \n",
              "50%         73.600000       26.000000       41.000000    66.000000   \n",
              "75%         85.397500       33.000000       51.000000    76.000000   \n",
              "max        100.000000       39.000000       69.000000   108.000000   \n",
              "\n",
              "              Age  Digital Learning Hours  Homework Submission Rate  \\\n",
              "count  500.000000               500.00000                500.000000   \n",
              "mean    11.906000                 6.83400                 75.523780   \n",
              "std      1.370007                 4.36997                 18.493879   \n",
              "min     10.000000                 0.00000                 28.140000   \n",
              "25%     11.000000                 3.00000                 63.372500   \n",
              "50%     12.000000                 7.00000                 76.775000   \n",
              "75%     13.000000                11.00000                 90.207500   \n",
              "max     14.000000                14.00000                100.000000   \n",
              "\n",
              "       Disciplinary Records  Student-Teacher Ratio  Guardian Contact  \n",
              "count            500.000000             500.000000      5.000000e+02  \n",
              "mean               1.638000              40.074000      9.490842e+09  \n",
              "std                1.436343              11.203909      2.903547e+08  \n",
              "min                0.000000              20.000000      9.006724e+09  \n",
              "25%                0.000000              31.000000      9.246982e+09  \n",
              "50%                1.000000              39.000000      9.486857e+09  \n",
              "75%                3.000000              50.000000      9.745784e+09  \n",
              "max                4.000000              59.000000      9.991747e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87bf180f-eef0-451e-af26-4b339433f96c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attendance (%)</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total Marks</th>\n",
              "      <th>Age</th>\n",
              "      <th>Digital Learning Hours</th>\n",
              "      <th>Homework Submission Rate</th>\n",
              "      <th>Disciplinary Records</th>\n",
              "      <th>Student-Teacher Ratio</th>\n",
              "      <th>Guardian Contact</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.00000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>5.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>72.629400</td>\n",
              "      <td>24.912000</td>\n",
              "      <td>40.770000</td>\n",
              "      <td>65.682000</td>\n",
              "      <td>11.906000</td>\n",
              "      <td>6.83400</td>\n",
              "      <td>75.523780</td>\n",
              "      <td>1.638000</td>\n",
              "      <td>40.074000</td>\n",
              "      <td>9.490842e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.082218</td>\n",
              "      <td>9.072203</td>\n",
              "      <td>12.046382</td>\n",
              "      <td>15.117074</td>\n",
              "      <td>1.370007</td>\n",
              "      <td>4.36997</td>\n",
              "      <td>18.493879</td>\n",
              "      <td>1.436343</td>\n",
              "      <td>11.203909</td>\n",
              "      <td>2.903547e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>30.390000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>28.140000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>9.006724e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>62.457500</td>\n",
              "      <td>16.750000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>63.372500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>9.246982e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>73.600000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>76.775000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>9.486857e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>85.397500</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.00000</td>\n",
              "      <td>90.207500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>9.745784e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>9.991747e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87bf180f-eef0-451e-af26-4b339433f96c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87bf180f-eef0-451e-af26-4b339433f96c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87bf180f-eef0-451e-af26-4b339433f96c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6fbf386-fa91-4988-ad0a-9db42fc3e8a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6fbf386-fa91-4988-ad0a-9db42fc3e8a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6fbf386-fa91-4988-ad0a-9db42fc3e8a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Attendance (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 156.88253485002963,\n        \"min\": 17.082218146177244,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          72.62939999999999,\n          73.6,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Internal Marks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169.0849876534913,\n        \"min\": 9.072202915029123,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          24.912,\n          26.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"External Marks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 164.41383977377149,\n        \"min\": 12.046382471983968,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.77,\n          41.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Marks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 158.30696133408952,\n        \"min\": 15.117074050745115,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          65.682,\n          66.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173.11967673050492,\n        \"min\": 1.3700065093536347,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          11.906,\n          12.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Digital Learning Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174.49865046388834,\n        \"min\": 0.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.834,\n          7.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Homework Submission Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 156.51359881007926,\n        \"min\": 18.493878809444944,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          75.52378,\n          76.775,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Disciplinary Records\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 176.22271747291455,\n        \"min\": 0.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          500.0,\n          1.638,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Student-Teacher Ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 164.85051039585312,\n        \"min\": 11.203909101662543,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.074,\n          39.0,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Guardian Contact\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4338788716.893754,\n        \"min\": 500.0,\n        \"max\": 9991747430.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          9490841902.158,\n          9486857416.5,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# For demonstration, assume missing values in numeric columns can be imputed with the mean\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
        "\n",
        "# For categorical columns, we can fill missing entries with \"Unknown\"\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].fillna(\"Unknown\")\n"
      ],
      "metadata": {
        "id": "9JkF5O3Ice1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9e0164-75ae-4835-83e7-56eb8033feed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student ID                    0\n",
            "Student Name                  0\n",
            "Student ID.1                  0\n",
            "Attendance (%)                0\n",
            "Internal Marks                0\n",
            "External Marks                0\n",
            "Total Marks                   0\n",
            "Grade                         0\n",
            "Gender                        0\n",
            "Age                           0\n",
            "Religion/Caste                0\n",
            "BPL Status                    0\n",
            "Parent Education Level      183\n",
            "Family Income Range           0\n",
            "DIKSHA Access                 0\n",
            "Digital Learning Hours        0\n",
            "Participation in Quiz         0\n",
            "Homework Submission Rate      0\n",
            "Disciplinary Records          0\n",
            "School Name                   0\n",
            "District                      0\n",
            "Student-Teacher Ratio         0\n",
            "Electricity                   0\n",
            "Toilet Facilities             0\n",
            "Library                       0\n",
            "Guardian Contact              0\n",
            "Preferred Mode                0\n",
            "Father Name                   0\n",
            "Mother Name                   0\n",
            "Class                         0\n",
            "Section                       0\n",
            "Class-Section                 0\n",
            "Teacher                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don’t already have a column indicating dropout risk, you need to create one. For demonstration, we’ll define dropout risk as a binary value where students with attendance below (for example) 60% are marked as “at risk.” You might base this on multiple factors (e.g., low marks and high disciplinary records) in a real scenario."
      ],
      "metadata": {
        "id": "eUswmY3se8IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a synthetic dropout risk variable based on Attendance (%)\n",
        "# You might also want to combine other variables (like Total Marks, Disciplinary Records, etc.)\n",
        "df['Dropout_Risk'] = np.where(df['Attendance (%)'] < 60, 1, 0)"
      ],
      "metadata": {
        "id": "ZOAHs3e5cvu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical features must be encoded. Numerical features may be scaled. One simple approach is to use label encoding or one-hot encoding for the categorical variables."
      ],
      "metadata": {
        "id": "1VMJL413fAye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Identify features (X) and target (y)\n",
        "y = df['Dropout_Risk']\n",
        "X = df.drop(columns=['Dropout_Risk'])\n",
        "\n",
        "# For simplicity, let’s use one-hot encoding for categorical variables.\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
        "    X_encoded.select_dtypes(include=['float64', 'int64']))"
      ],
      "metadata": {
        "id": "4z5Trliyc32m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd699852-b834-448a-a385-9d11566efcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.98332516  0.12004688  0.45105849  1.44409332 -1.31433677  1.55443053\n",
            " -1.20399957  0.7820701  -0.98332516 -0.32130194 -0.10062753 -0.54197635\n",
            "  1.44409332 -1.31433677 -0.32130194 -0.98332516  1.22341892  0.34072129\n",
            "  0.6717329   1.33375612 -1.53501118 -0.65231355 -0.32130194  1.55443053\n",
            "  1.00274451  0.56139569 -1.09366236  1.33375612  1.33375612 -0.43163914\n",
            " -0.43163914  0.45105849  1.55443053  1.55443053 -0.54197635  1.11308171\n",
            "  0.7820701   1.33375612  1.00274451 -0.98332516  1.55443053 -1.64534838\n",
            " -1.64534838  1.00274451  1.22341892  1.55443053  1.00274451  0.45105849\n",
            " -0.32130194 -0.76265075 -1.42467398 -0.98332516 -1.09366236 -0.87298796\n",
            "  1.22341892 -0.76265075  1.55443053 -1.20399957 -1.64534838  0.34072129\n",
            " -0.65231355 -0.43163914  0.8924073  -0.10062753  1.22341892  0.6717329\n",
            "  0.8924073  -0.76265075  0.45105849  0.12004688  1.55443053  0.12004688\n",
            "  1.11308171  0.45105849 -0.43163914  1.55443053 -0.98332516 -1.53501118\n",
            " -1.42467398  0.12004688 -1.20399957  0.12004688  0.8924073   0.12004688\n",
            "  1.22341892  0.12004688 -1.53501118 -1.53501118  1.33375612  0.6717329\n",
            "  0.7820701  -1.20399957 -1.64534838 -1.64534838  0.34072129  1.55443053\n",
            " -1.53501118  0.56139569 -0.43163914  1.11308171 -0.54197635  0.56139569\n",
            " -1.53501118  1.33375612 -0.76265075  0.56139569 -1.42467398  0.6717329\n",
            " -1.31433677  0.8924073  -1.42467398 -0.76265075 -0.43163914 -1.64534838\n",
            "  1.33375612 -0.98332516  0.6717329   0.45105849  1.00274451 -0.76265075\n",
            "  0.8924073   0.6717329   1.11308171  0.45105849  1.44409332  0.34072129\n",
            " -1.64534838 -0.98332516  0.7820701  -0.54197635  1.00274451 -0.76265075\n",
            " -0.87298796  0.6717329   1.33375612  0.12004688  0.56139569 -1.42467398\n",
            " -0.10062753 -0.76265075  1.33375612  0.00970967  0.6717329   0.45105849\n",
            " -0.43163914  0.7820701   0.34072129 -1.64534838  1.44409332 -1.20399957\n",
            "  1.55443053  1.55443053  1.11308171 -1.53501118  0.34072129  1.44409332\n",
            "  1.44409332 -0.32130194 -0.65231355 -0.98332516  1.55443053  0.12004688\n",
            " -0.21096473  1.00274451 -0.98332516 -0.10062753  0.23038408  0.45105849\n",
            "  1.44409332 -0.32130194 -1.64534838 -1.09366236 -1.20399957 -0.10062753\n",
            " -0.65231355 -0.87298796  0.45105849 -1.53501118 -1.64534838  1.22341892\n",
            " -1.20399957 -0.21096473 -0.87298796  0.23038408  0.7820701   1.33375612\n",
            " -1.53501118 -1.20399957 -1.53501118 -0.87298796  1.11308171 -1.09366236\n",
            "  1.11308171  0.12004688 -0.32130194 -0.54197635  1.33375612 -1.31433677\n",
            " -1.53501118 -1.53501118  0.00970967 -1.31433677  0.12004688  0.34072129\n",
            " -0.43163914 -1.42467398 -1.64534838 -1.42467398 -1.64534838  0.56139569\n",
            " -0.32130194 -1.64534838 -1.42467398  1.55443053  1.22341892  0.6717329\n",
            " -0.87298796  1.11308171  0.7820701  -0.54197635 -0.65231355 -1.31433677\n",
            "  0.56139569  1.00274451  0.12004688  1.11308171  0.45105849 -0.32130194\n",
            "  1.44409332  0.6717329  -0.98332516  1.33375612  1.44409332 -0.87298796\n",
            "  0.56139569  0.00970967 -1.53501118 -1.53501118  1.22341892 -0.32130194\n",
            " -1.09366236 -1.09366236  1.00274451 -0.21096473  1.11308171 -1.42467398\n",
            "  0.45105849 -0.76265075 -1.42467398  0.12004688 -0.87298796  1.00274451\n",
            " -0.21096473 -0.98332516 -1.42467398 -0.98332516  0.00970967  1.22341892\n",
            "  0.00970967  0.23038408 -0.10062753 -0.98332516 -0.32130194  0.6717329\n",
            "  1.55443053 -1.53501118 -1.53501118  1.33375612  0.12004688  1.22341892\n",
            "  1.22341892 -0.98332516 -0.54197635 -1.53501118  0.8924073  -0.10062753\n",
            "  1.22341892  0.8924073   1.44409332 -0.54197635  1.44409332 -1.42467398\n",
            "  1.22341892 -1.09366236 -0.43163914 -0.10062753 -0.21096473  1.00274451\n",
            "  0.12004688  1.00274451 -0.76265075  0.23038408 -1.09366236  0.12004688\n",
            " -0.76265075 -1.09366236 -0.32130194  0.23038408  1.44409332  0.8924073\n",
            "  0.34072129 -1.53501118  0.56139569 -0.65231355  0.6717329   1.00274451\n",
            "  0.8924073   1.55443053  0.45105849  0.8924073  -1.20399957 -1.20399957\n",
            "  0.8924073   0.7820701  -0.10062753  0.12004688  0.00970967 -1.09366236\n",
            " -0.76265075 -1.09366236  0.8924073   0.34072129  1.11308171  1.11308171\n",
            " -1.53501118  1.22341892 -0.10062753  0.56139569  1.55443053 -0.98332516\n",
            " -0.65231355  0.6717329   1.44409332 -1.31433677  0.23038408  0.6717329\n",
            "  1.00274451 -0.98332516 -0.98332516 -1.09366236  0.56139569 -1.42467398\n",
            " -0.10062753  1.55443053  1.00274451  0.00970967 -0.32130194 -1.42467398\n",
            "  0.6717329   0.8924073  -1.53501118  1.00274451  0.00970967 -1.53501118\n",
            " -0.32130194  0.34072129 -0.76265075  0.34072129  0.45105849  1.44409332\n",
            " -1.09366236  1.11308171  1.33375612 -1.42467398 -0.76265075 -0.54197635\n",
            " -0.32130194  1.00274451 -0.21096473  1.11308171  0.12004688  1.55443053\n",
            " -0.87298796 -0.87298796  0.6717329   0.56139569 -0.32130194 -0.10062753\n",
            " -0.54197635 -1.20399957 -1.42467398 -0.98332516 -0.65231355  0.00970967\n",
            " -0.65231355  0.56139569  1.44409332  0.8924073   0.12004688  0.34072129\n",
            "  1.33375612  0.00970967  1.44409332  0.12004688  0.12004688 -0.98332516\n",
            "  1.33375612 -0.21096473  0.8924073  -0.98332516  0.8924073   1.11308171\n",
            "  1.00274451 -0.98332516 -0.65231355 -0.43163914  0.45105849 -0.21096473\n",
            " -0.87298796  1.22341892  1.33375612 -0.65231355  0.7820701   0.6717329\n",
            "  0.56139569  0.7820701  -1.42467398 -0.43163914 -1.42467398 -1.53501118\n",
            " -1.20399957 -1.42467398  0.7820701   1.00274451 -1.09366236  1.55443053\n",
            " -0.21096473  0.45105849 -0.87298796 -0.76265075  0.6717329  -0.21096473\n",
            "  1.44409332 -0.10062753  1.44409332  1.33375612 -1.53501118  1.11308171\n",
            " -1.42467398  0.12004688  0.12004688 -0.98332516 -1.64534838 -0.43163914\n",
            "  0.23038408  1.33375612 -0.98332516 -0.21096473  1.22341892 -0.54197635\n",
            "  1.00274451 -1.42467398 -1.42467398  1.11308171  0.8924073   1.33375612\n",
            " -1.20399957 -0.32130194 -0.54197635  1.55443053  0.23038408 -1.31433677\n",
            "  1.22341892  0.12004688  1.33375612  0.12004688  0.56139569  1.22341892\n",
            "  0.8924073   0.45105849  1.22341892 -0.10062753  0.12004688  0.7820701\n",
            " -0.65231355  1.55443053 -1.64534838 -1.53501118 -0.32130194 -0.87298796\n",
            "  1.11308171  0.7820701   0.56139569  0.12004688  0.23038408 -1.31433677\n",
            "  0.23038408  0.6717329  -0.54197635  0.23038408 -1.20399957  0.8924073\n",
            " -0.54197635  0.34072129 -0.76265075 -0.32130194 -1.64534838 -1.31433677\n",
            " -1.64534838  0.6717329 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.85006809 -1.31041777  0.85006809 -1.47660899 -0.89493972 -0.39636606\n",
            "  1.34864175  0.18530321 -1.39351338  1.01625931 -1.31041777  0.01911199\n",
            " -0.89493972  2.17959786 -0.47946167  0.9331637  -1.06113094 -1.31041777\n",
            " -0.47946167  0.60078126 -1.5597046  -0.14707923  1.18245053 -0.23017484\n",
            "  0.35149443 -1.5597046  -0.23017484 -0.14707923  0.85006809 -1.22732216\n",
            "  1.59792858  0.9331637   1.51483297  1.43173736 -0.31327045  1.51483297\n",
            " -1.72589582 -0.89493972  0.51768565  0.26839882  2.34578908  0.1022076\n",
            "  0.76697248  0.68387687  1.68102419  1.09935492 -1.22732216 -0.47946167\n",
            "  0.35149443  2.17959786  2.26269347 -1.64280021 -1.72589582  2.17959786\n",
            " -0.81184411 -1.39351338  1.26554614  0.85006809 -1.06113094  1.59792858\n",
            "  1.09935492 -0.23017484  2.17959786 -0.47946167 -1.5597046  -0.14707923\n",
            "  0.18530321  0.9331637   0.18530321 -0.89493972  2.26269347 -1.14422655\n",
            "  1.18245053  1.34864175  1.51483297 -0.14707923  1.09935492  2.17959786\n",
            "  0.26839882  1.09935492  0.26839882  0.60078126 -0.31327045  2.01340664\n",
            " -0.31327045 -1.64280021  1.09935492 -0.47946167  1.59792858  1.18245053\n",
            "  0.9331637  -1.47660899  0.9331637  -0.64565289 -0.06398362  2.17959786\n",
            " -0.14707923 -1.14422655 -1.22732216 -1.5597046  -1.14422655  1.18245053\n",
            " -0.06398362 -0.47946167  1.43173736 -1.64280021 -0.64565289 -1.47660899\n",
            " -0.64565289  0.35149443  1.09935492 -1.14422655  1.51483297 -1.39351338\n",
            " -0.7287485  -0.56255728  0.51768565  0.68387687  0.43459004  1.26554614\n",
            " -0.81184411  0.1022076   0.85006809  1.01625931 -1.5597046  -0.14707923\n",
            " -0.89493972 -0.47946167 -1.06113094 -1.14422655  0.60078126  1.18245053\n",
            " -1.22732216  0.68387687  0.9331637   0.51768565  0.76697248 -0.31327045\n",
            "  0.01911199  1.43173736 -1.22732216 -0.64565289  0.26839882 -1.31041777\n",
            " -1.39351338  1.51483297  0.51768565 -1.72589582  1.43173736  0.01911199\n",
            " -1.39351338  1.26554614 -0.23017484  0.51768565  1.26554614 -0.7287485\n",
            "  0.35149443 -0.89493972  1.26554614  0.85006809 -0.39636606  1.18245053\n",
            "  0.76697248 -0.06398362 -0.64565289 -0.81184411  0.43459004 -0.39636606\n",
            "  1.43173736  0.51768565 -1.5597046   0.85006809  1.18245053  0.76697248\n",
            "  0.85006809  0.51768565 -0.7287485  -0.97803533 -0.31327045 -0.7287485\n",
            "  0.76697248 -1.06113094  0.85006809 -0.81184411 -0.56255728  1.01625931\n",
            "  1.34864175  0.60078126 -0.7287485  -1.47660899 -0.23017484 -1.72589582\n",
            "  0.01911199  1.09935492  0.35149443 -0.31327045 -0.97803533 -0.97803533\n",
            " -1.14422655 -1.31041777 -1.47660899  0.18530321  0.68387687 -1.39351338\n",
            " -1.72589582  0.9331637   1.26554614  0.68387687  1.51483297  1.26554614\n",
            "  0.26839882  0.26839882 -1.22732216  1.43173736  0.9331637   1.34864175\n",
            " -1.39351338  0.43459004  0.35149443 -0.81184411  0.51768565  0.1022076\n",
            " -1.06113094  0.35149443  0.18530321  0.51768565  0.01911199  0.68387687\n",
            "  0.68387687  0.51768565 -1.5597046   0.85006809 -1.14422655  1.01625931\n",
            " -0.64565289 -0.23017484 -1.5597046   1.09935492  0.1022076   0.26839882\n",
            " -0.31327045 -0.81184411 -1.22732216 -1.64280021  0.60078126  1.01625931\n",
            " -0.39636606 -1.06113094  1.26554614 -0.39636606  0.76697248 -0.81184411\n",
            " -0.56255728  1.09935492  1.01625931 -0.56255728 -1.64280021  1.43173736\n",
            " -0.97803533 -1.47660899 -1.06113094  0.18530321 -0.97803533  0.1022076\n",
            " -0.39636606 -0.89493972 -0.81184411 -0.56255728  1.51483297 -0.7287485\n",
            " -0.7287485  -1.39351338  0.68387687  0.85006809  1.09935492  0.68387687\n",
            " -0.39636606 -0.31327045 -0.81184411  0.1022076   0.60078126 -0.39636606\n",
            " -0.14707923 -0.56255728 -0.47946167  0.43459004 -0.56255728  0.01911199\n",
            " -1.14422655  0.9331637  -0.39636606  0.9331637   1.43173736  1.51483297\n",
            " -0.81184411  0.01911199 -0.23017484 -0.23017484  0.60078126 -0.14707923\n",
            "  0.85006809  1.18245053 -0.56255728 -0.64565289 -0.64565289  0.51768565\n",
            "  1.18245053 -1.72589582  0.51768565  0.51768565 -0.14707923  0.9331637\n",
            "  0.1022076  -1.14422655  0.01911199 -0.81184411 -0.64565289 -1.06113094\n",
            " -0.89493972  1.01625931 -1.22732216  0.60078126 -0.89493972 -1.14422655\n",
            "  1.26554614 -0.06398362 -1.47660899  0.43459004 -0.31327045  0.76697248\n",
            "  1.18245053  0.51768565 -1.14422655  1.43173736 -1.39351338  1.26554614\n",
            "  0.26839882 -0.89493972  1.18245053  1.43173736 -1.14422655  1.01625931\n",
            " -0.47946167  0.1022076   0.68387687 -0.81184411 -1.64280021  0.1022076\n",
            "  1.26554614  0.68387687  0.43459004 -1.64280021 -1.5597046  -1.47660899\n",
            "  0.76697248 -1.39351338  0.1022076  -1.22732216  1.18245053  1.09935492\n",
            " -0.56255728 -0.06398362 -0.89493972  0.60078126 -1.72589582  1.01625931\n",
            " -0.23017484  0.1022076   1.18245053 -1.39351338  0.76697248 -1.47660899\n",
            " -1.64280021 -0.31327045  0.68387687  1.09935492 -0.06398362  0.43459004\n",
            "  1.26554614 -1.14422655  0.85006809  0.43459004  0.35149443  0.76697248\n",
            "  0.18530321 -0.97803533 -0.64565289  0.18530321 -0.23017484  1.18245053\n",
            " -0.89493972  0.43459004 -0.97803533 -0.23017484 -0.06398362  1.09935492\n",
            "  0.76697248 -0.97803533 -0.14707923 -1.31041777 -0.64565289  1.26554614\n",
            " -1.22732216  0.01911199 -0.06398362  0.18530321  0.35149443  0.43459004\n",
            "  0.9331637  -0.23017484  1.18245053 -0.14707923 -1.14422655 -0.23017484\n",
            " -0.06398362  0.43459004  0.51768565 -0.89493972 -0.81184411 -0.31327045\n",
            " -0.89493972  1.51483297 -1.5597046  -0.64565289  0.43459004  1.09935492\n",
            "  0.35149443 -1.22732216 -0.39636606 -1.47660899 -0.47946167 -0.06398362\n",
            " -1.06113094  1.51483297  0.01911199  0.51768565  0.43459004  0.43459004\n",
            "  1.51483297 -1.14422655 -1.06113094  1.43173736  1.51483297  0.9331637\n",
            " -0.31327045  1.51483297 -1.64280021 -0.31327045 -1.64280021 -1.72589582\n",
            "  0.1022076  -1.06113094 -1.5597046   1.18245053 -1.72589582  1.09935492\n",
            " -1.14422655 -1.39351338  0.43459004  1.26554614 -1.06113094 -1.39351338\n",
            "  0.1022076  -0.06398362  0.18530321  1.09935492 -1.14422655  1.01625931\n",
            " -0.14707923  0.85006809 -0.89493972 -1.47660899  0.9331637  -0.47946167\n",
            " -0.06398362  1.09935492 -0.56255728  1.51483297  0.85006809 -0.39636606\n",
            " -0.7287485   0.43459004 -0.7287485   0.1022076  -0.64565289 -0.7287485\n",
            "  1.01625931  1.34864175 -1.72589582 -0.56255728 -0.39636606 -0.97803533\n",
            " -0.39636606 -0.81184411  1.09935492  1.18245053  1.18245053 -0.31327045\n",
            "  1.18245053 -0.97803533]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.0872735  -0.97219237  0.94808952 -0.3100262  -1.50192531  0.61700644\n",
            "  0.35213997  0.61700644 -1.70057516  0.61700644 -1.1046256  -0.3100262\n",
            "  0.15349012  0.94808952 -0.57489267  0.15349012 -0.11137635 -0.83975914\n",
            "  0.02105688  1.27917261 -2.16409148 -0.50867605  0.74943967  0.74943967\n",
            "  0.88187291 -0.90597575 -0.83975914  0.68322305  1.47782246 -1.23705884\n",
            "  1.01430614  1.01430614  2.13998863  2.07377201 -0.57489267  1.87512216\n",
            " -0.90597575  0.0872735   1.01430614 -0.37624282  2.8021548  -0.90597575\n",
            " -0.37624282  1.14673937  2.07377201  1.80890554 -0.37624282 -0.11137635\n",
            "  0.0872735   1.27917261  0.94808952 -1.89922501 -2.03165824  1.21295599\n",
            "  0.0872735  -1.56814192  1.94133878 -0.04515973 -1.83300839  1.47782246\n",
            "  0.4845732  -0.44245943  2.27242186 -0.44245943 -0.50867605  0.28592335\n",
            "  0.68322305  0.28592335  0.41835659 -0.64110929  2.73593818 -0.83975914\n",
            "  1.61025569  1.34538922  0.94808952  0.81565629  0.28592335  0.81565629\n",
            " -0.64110929  0.94808952 -0.50867605  0.55078982  0.28592335  1.67647231\n",
            "  0.4845732  -1.23705884 -0.04515973 -1.30327546  2.07377201  1.34538922\n",
            "  1.21295599 -1.89922501 -0.24380958 -1.50192531  0.15349012  2.66972156\n",
            " -1.03840899 -0.57489267 -1.23705884 -0.57489267 -1.23705884  1.27917261\n",
            " -0.97219237  0.41835659  0.68322305 -0.97219237 -1.36949207 -0.77354252\n",
            " -1.30327546  0.81565629  0.02105688 -1.36949207  0.94808952 -2.09787486\n",
            "  0.21970674 -1.03840899  0.81565629  0.81565629  0.94808952  0.55078982\n",
            " -0.11137635  0.4845732   1.34538922  1.08052276 -0.37624282  0.0872735\n",
            " -1.70057516 -0.97219237 -0.37624282 -1.23705884  1.08052276  0.4845732\n",
            " -1.50192531  0.94808952  1.54403908  0.4845732   0.94808952 -1.1046256\n",
            " -0.04515973  0.68322305 -0.17759297 -0.50867605  0.61700644 -0.77354252\n",
            " -1.36949207  1.67647231  0.61700644 -2.36274133  2.00755539 -0.7073259\n",
            " -0.17759297  1.94133878  0.4845732  -0.50867605  1.21295599  0.28592335\n",
            "  1.14673937 -0.90597575  0.61700644  0.0872735   0.61700644  1.01430614\n",
            "  0.4845732   0.55078982 -1.1046256  -0.7073259   0.4845732  -0.04515973\n",
            "  2.00755539  0.21970674 -2.23030809  0.02105688  0.21970674  0.55078982\n",
            "  0.28592335 -0.11137635 -0.3100262  -1.70057516 -1.23705884  0.15349012\n",
            " -0.11137635 -0.97219237  0.15349012 -0.50867605  0.02105688  1.61025569\n",
            "  0.15349012 -0.24380958 -1.50192531 -1.70057516  0.4845732  -2.03165824\n",
            "  0.68322305  0.94808952  0.0872735  -0.57489267  0.02105688 -1.56814192\n",
            " -1.83300839 -1.96544163 -1.17084222 -0.64110929  0.61700644 -0.90597575\n",
            " -1.63435854 -0.11137635  0.02105688 -0.3100262   0.21970674  1.34538922\n",
            "  0.02105688 -0.77354252 -1.83300839  2.07377201  1.47782246  1.47782246\n",
            " -1.63435854  1.01430614  0.74943967 -0.97219237  0.02105688 -0.7073259\n",
            " -0.50867605  0.88187291  0.21970674  1.08052276  0.28592335  0.35213997\n",
            "  1.41160584  0.81565629 -1.83300839  1.47782246 -0.04515973  0.28592335\n",
            " -0.17759297 -0.17759297 -2.16409148 -0.04515973  0.81565629  0.02105688\n",
            " -0.90597575 -1.30327546 -0.37624282 -1.43570869  1.14673937 -0.04515973\n",
            " -0.04515973 -1.30327546  0.15349012 -0.24380958  0.0872735  -0.04515973\n",
            " -0.57489267  0.28592335 -0.04515973 -1.03840899 -1.30327546  1.87512216\n",
            " -0.77354252 -1.03840899 -0.90597575 -0.44245943 -0.97219237  0.4845732\n",
            "  0.61700644 -1.63435854 -1.56814192  0.35213997  1.27917261  0.15349012\n",
            "  0.15349012 -1.70057516  0.21970674 -0.24380958  1.41160584  0.4845732\n",
            "  0.41835659  0.28592335  0.21970674 -0.24380958  1.34538922 -1.17084222\n",
            "  0.61700644 -1.1046256  -0.64110929  0.28592335 -0.57489267  0.61700644\n",
            " -0.83975914  1.34538922 -0.77354252  0.88187291  0.4845732   1.27917261\n",
            " -1.1046256  -0.64110929 -0.37624282 -0.04515973  1.34538922  0.41835659\n",
            "  0.88187291  0.02105688 -0.11137635 -0.90597575 -0.11137635  1.01430614\n",
            "  1.47782246 -0.44245943  0.68322305  0.94808952 -0.83975914  0.02105688\n",
            "  0.61700644 -0.44245943 -0.04515973 -0.57489267 -0.50867605 -1.50192531\n",
            " -1.17084222  0.15349012 -0.44245943  0.68322305 -0.04515973 -0.24380958\n",
            "  0.0872735   0.68322305 -1.23705884  0.68322305  0.68322305  0.02105688\n",
            "  0.55078982  0.81565629 -0.04515973  0.35213997 -0.97219237  1.41160584\n",
            "  0.81565629 -1.30327546  0.35213997  0.4845732  -0.57489267 -0.04515973\n",
            " -0.44245943  1.01430614  1.14673937 -0.64110929 -1.50192531 -0.77354252\n",
            "  1.41160584  1.08052276 -0.57489267 -0.7073259  -1.23705884 -2.09787486\n",
            "  0.41835659 -0.90597575 -0.37624282 -0.77354252  1.21295599  1.74268893\n",
            " -1.1046256   0.61700644  0.0872735  -0.37624282 -1.83300839  0.4845732\n",
            " -0.37624282  0.68322305  0.81565629 -0.44245943  0.68322305 -0.24380958\n",
            " -1.83300839 -0.77354252  0.94808952  1.21295599 -0.24380958  0.28592335\n",
            "  0.68322305 -1.63435854 -0.17759297 -0.24380958 -0.11137635  0.61700644\n",
            " -0.24380958 -0.44245943  0.35213997  0.68322305 -0.11137635  1.14673937\n",
            "  0.0872735   0.35213997  0.0872735  -0.11137635  0.02105688  0.28592335\n",
            "  1.41160584 -0.90597575  0.41835659 -1.63435854  0.02105688  1.67647231\n",
            " -0.37624282 -0.57489267 -0.44245943 -0.11137635  0.55078982  0.21970674\n",
            "  0.21970674  0.55078982  1.74268893 -0.50867605 -0.44245943  0.21970674\n",
            "  0.28592335  0.81565629 -0.44245943 -0.97219237 -1.50192531 -1.17084222\n",
            " -1.43570869  0.35213997 -0.77354252  0.0872735  -0.3100262   1.80890554\n",
            "  0.15349012 -0.7073259  -0.83975914 -1.63435854  0.02105688 -0.17759297\n",
            "  0.02105688  1.14673937  0.88187291  1.21295599 -0.57489267  1.01430614\n",
            "  0.35213997 -0.83975914 -0.77354252  0.55078982  0.21970674  0.4845732\n",
            " -0.11137635  2.00755539 -1.89922501 -0.37624282 -0.57489267 -1.70057516\n",
            "  0.68322305 -1.70057516 -2.09787486  1.61025569 -0.83975914  1.67647231\n",
            " -1.63435854 -1.30327546  0.02105688  1.94133878 -0.7073259  -1.89922501\n",
            "  0.81565629  0.02105688  0.94808952  0.94808952 -0.57489267  1.54403908\n",
            "  0.41835659  0.94808952  0.02105688 -1.23705884  0.81565629  0.0872735\n",
            " -0.44245943  1.80890554 -1.43570869  0.28592335  0.4845732  -0.83975914\n",
            "  0.0872735   0.81565629 -0.24380958  0.15349012 -0.37624282 -1.36949207\n",
            "  0.94808952  1.47782246 -1.70057516 -0.3100262  -1.03840899 -0.24380958\n",
            " -0.64110929 -0.44245943  0.41835659  0.74943967 -0.04515973 -1.03840899\n",
            " -0.04515973 -0.37624282]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.06868153 -0.66197303  0.06868153 -0.66197303 -1.39262759  0.79933609\n",
            " -1.39262759  0.79933609 -0.66197303  0.06868153 -1.39262759  0.79933609\n",
            " -1.39262759  0.79933609 -1.39262759  0.79933609  0.79933609 -0.66197303\n",
            "  0.79933609 -0.66197303  0.79933609  0.06868153  0.06868153  0.06868153\n",
            "  0.79933609 -0.66197303 -0.66197303  0.79933609  0.06868153  0.06868153\n",
            " -0.66197303  0.06868153 -1.39262759 -0.66197303  0.06868153 -0.66197303\n",
            " -1.39262759 -0.66197303 -0.66197303 -0.66197303 -0.66197303 -1.39262759\n",
            "  0.79933609 -0.66197303 -0.66197303  0.06868153 -0.66197303  0.06868153\n",
            "  0.79933609 -1.39262759 -1.39262759  0.79933609 -1.39262759  0.79933609\n",
            "  0.79933609  0.79933609 -1.39262759  0.06868153  0.79933609 -0.66197303\n",
            " -1.39262759  0.79933609  0.79933609 -0.66197303  0.06868153  0.06868153\n",
            "  0.06868153  0.79933609  0.79933609  0.79933609 -1.39262759 -0.66197303\n",
            "  0.79933609 -0.66197303 -0.66197303  0.06868153 -1.39262759  0.79933609\n",
            "  0.06868153  0.06868153  0.79933609 -0.66197303  0.06868153 -0.66197303\n",
            " -1.39262759 -0.66197303 -1.39262759 -0.66197303  0.06868153  0.06868153\n",
            " -1.39262759  0.79933609 -1.39262759 -1.39262759 -0.66197303 -0.66197303\n",
            " -1.39262759  0.06868153 -0.66197303  0.79933609  1.52999065  0.06868153\n",
            " -1.39262759  0.06868153 -0.66197303  0.79933609 -1.39262759  1.52999065\n",
            "  0.79933609 -1.39262759 -1.39262759  0.79933609  0.06868153 -0.66197303\n",
            "  0.06868153  0.06868153 -0.66197303  0.06868153 -1.39262759 -1.39262759\n",
            " -0.66197303  1.52999065  0.79933609  0.06868153  0.79933609  0.79933609\n",
            "  0.79933609 -0.66197303 -1.39262759  0.79933609 -0.66197303 -1.39262759\n",
            "  0.06868153  1.52999065  1.52999065  1.52999065  0.06868153 -1.39262759\n",
            " -0.66197303  1.52999065 -1.39262759  0.79933609 -0.66197303  0.06868153\n",
            "  0.79933609  0.79933609 -0.66197303 -0.66197303  1.52999065 -1.39262759\n",
            "  0.79933609 -0.66197303 -0.66197303  0.06868153  0.79933609  0.79933609\n",
            " -0.66197303  1.52999065 -1.39262759  1.52999065 -1.39262759  0.79933609\n",
            "  0.79933609  0.79933609 -0.66197303 -1.39262759 -0.66197303 -1.39262759\n",
            "  0.06868153 -0.66197303  1.52999065  1.52999065  0.06868153 -1.39262759\n",
            "  0.79933609  0.79933609  0.79933609 -0.66197303 -1.39262759 -1.39262759\n",
            "  1.52999065 -1.39262759 -0.66197303 -1.39262759  1.52999065 -0.66197303\n",
            " -1.39262759  0.79933609  0.06868153 -1.39262759  1.52999065  1.52999065\n",
            "  0.06868153  1.52999065  0.06868153 -0.66197303 -1.39262759  0.06868153\n",
            " -1.39262759  1.52999065  0.06868153 -0.66197303  0.06868153 -0.66197303\n",
            " -0.66197303 -0.66197303 -1.39262759 -1.39262759  0.79933609  1.52999065\n",
            " -0.66197303 -1.39262759  0.06868153  0.06868153  0.79933609  1.52999065\n",
            "  1.52999065  1.52999065  0.06868153  0.79933609 -0.66197303 -1.39262759\n",
            " -0.66197303  0.06868153 -1.39262759 -0.66197303  0.79933609  0.06868153\n",
            "  0.06868153 -1.39262759 -0.66197303 -0.66197303 -1.39262759  0.06868153\n",
            " -0.66197303  0.79933609  0.79933609  0.79933609 -1.39262759 -1.39262759\n",
            "  1.52999065  1.52999065 -0.66197303  0.79933609  1.52999065  1.52999065\n",
            "  0.06868153 -1.39262759  0.79933609 -0.66197303  1.52999065  0.06868153\n",
            "  1.52999065 -0.66197303  0.06868153 -1.39262759  0.06868153  0.79933609\n",
            " -1.39262759 -0.66197303 -1.39262759  0.06868153  0.06868153 -1.39262759\n",
            "  0.06868153 -1.39262759 -0.66197303  0.06868153  1.52999065  1.52999065\n",
            "  0.06868153  0.06868153 -0.66197303  1.52999065  0.06868153  1.52999065\n",
            "  0.79933609 -0.66197303  1.52999065 -0.66197303  0.06868153  0.79933609\n",
            "  0.06868153 -0.66197303  0.06868153 -0.66197303 -1.39262759  1.52999065\n",
            "  1.52999065  0.79933609  0.79933609 -0.66197303 -0.66197303  0.06868153\n",
            " -0.66197303 -0.66197303  0.79933609  1.52999065 -1.39262759  1.52999065\n",
            " -1.39262759 -0.66197303 -1.39262759 -0.66197303 -1.39262759 -0.66197303\n",
            "  1.52999065  1.52999065 -1.39262759  0.79933609 -0.66197303 -1.39262759\n",
            "  0.79933609 -0.66197303 -0.66197303  0.06868153  1.52999065 -1.39262759\n",
            "  0.79933609 -0.66197303 -1.39262759 -1.39262759  0.06868153 -0.66197303\n",
            "  0.79933609  0.06868153  1.52999065  1.52999065 -0.66197303  0.79933609\n",
            "  0.79933609 -1.39262759 -1.39262759 -0.66197303 -1.39262759  0.06868153\n",
            " -0.66197303  0.79933609  1.52999065  0.79933609 -0.66197303  0.79933609\n",
            " -0.66197303  0.79933609  1.52999065  0.79933609 -1.39262759 -0.66197303\n",
            "  0.79933609  0.06868153 -0.66197303 -1.39262759  0.06868153 -1.39262759\n",
            "  0.79933609  0.06868153  0.06868153  0.79933609  0.79933609  0.06868153\n",
            "  1.52999065  1.52999065  1.52999065  0.79933609 -0.66197303  0.06868153\n",
            "  1.52999065  0.06868153  0.06868153  1.52999065 -1.39262759 -1.39262759\n",
            "  1.52999065 -1.39262759  0.79933609 -0.66197303  0.79933609 -0.66197303\n",
            "  1.52999065 -0.66197303 -0.66197303  0.06868153 -0.66197303  0.06868153\n",
            "  0.06868153  0.79933609  0.06868153 -0.66197303  1.52999065 -1.39262759\n",
            " -1.39262759  0.79933609 -0.66197303 -0.66197303 -0.66197303 -1.39262759\n",
            "  0.79933609 -0.66197303 -0.66197303 -0.66197303 -1.39262759 -1.39262759\n",
            " -1.39262759 -1.39262759  1.52999065  0.79933609  0.79933609  1.52999065\n",
            " -0.66197303  1.52999065  1.52999065  0.79933609  1.52999065 -1.39262759\n",
            "  1.52999065  1.52999065  1.52999065 -0.66197303  0.79933609 -0.66197303\n",
            "  0.06868153  0.79933609  0.79933609  0.79933609  0.06868153  0.06868153\n",
            " -1.39262759 -1.39262759 -1.39262759  0.06868153  1.52999065  1.52999065\n",
            "  1.52999065  0.79933609  1.52999065  0.79933609 -1.39262759  0.06868153\n",
            "  0.06868153  0.06868153  1.52999065  1.52999065  0.79933609  1.52999065\n",
            " -0.66197303  0.79933609  1.52999065  0.06868153  1.52999065  1.52999065\n",
            " -1.39262759  1.52999065  0.79933609  0.79933609 -1.39262759  0.06868153\n",
            " -0.66197303  0.06868153 -0.66197303 -0.66197303 -1.39262759  1.52999065\n",
            "  0.06868153  0.79933609  1.52999065  0.79933609  0.79933609  0.06868153\n",
            " -1.39262759 -0.66197303 -1.39262759  1.52999065  0.06868153 -0.66197303\n",
            "  0.79933609  0.06868153  1.52999065 -1.39262759 -0.66197303 -0.66197303\n",
            "  0.79933609  1.52999065  1.52999065 -0.66197303 -0.66197303  0.06868153\n",
            "  0.06868153 -1.39262759  0.06868153  0.06868153 -0.66197303  1.52999065\n",
            "  0.79933609  1.52999065 -0.66197303 -0.66197303  1.52999065  0.06868153\n",
            "  1.52999065  1.52999065]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.26708828 -1.33635765  0.03802457  0.03802457 -0.19103913  0.03802457\n",
            "  1.4124068  -1.10729395  1.1833431  -0.42010283 -1.56542136 -0.19103913\n",
            "  1.64147051  1.64147051 -1.56542136  0.26708828 -1.56542136 -1.56542136\n",
            "  1.64147051 -0.19103913 -1.33635765  1.4124068  -0.64916654  0.03802457\n",
            "  0.03802457 -1.10729395 -0.19103913 -1.10729395 -0.42010283 -0.42010283\n",
            " -1.10729395 -0.19103913 -1.10729395  0.03802457  0.49615198 -0.87823024\n",
            "  1.64147051  1.64147051  1.1833431  -1.56542136 -0.87823024  1.4124068\n",
            " -0.19103913  0.72521569 -0.87823024  1.1833431  -0.42010283  0.26708828\n",
            " -1.56542136  1.1833431  -0.64916654  0.72521569 -0.19103913 -1.56542136\n",
            "  1.4124068  -0.87823024 -0.42010283 -1.33635765  0.49615198 -0.64916654\n",
            "  0.72521569  0.49615198 -1.56542136 -0.42010283 -0.42010283  1.1833431\n",
            "  1.64147051  1.64147051 -0.87823024  1.1833431   0.03802457 -0.87823024\n",
            "  0.03802457  1.64147051  1.1833431   0.03802457 -0.64916654  1.1833431\n",
            "  1.64147051 -0.87823024  0.95427939  1.1833431  -1.33635765  0.72521569\n",
            "  1.64147051 -1.10729395 -1.10729395 -0.87823024 -0.87823024  0.49615198\n",
            "  0.72521569  0.72521569 -0.64916654 -0.87823024  0.72521569  1.4124068\n",
            "  0.49615198  0.03802457 -0.42010283 -0.42010283 -0.64916654 -0.42010283\n",
            "  0.95427939  0.95427939 -0.87823024  0.95427939 -0.87823024  1.64147051\n",
            "  0.26708828  0.95427939  0.72521569 -1.33635765 -1.10729395 -0.19103913\n",
            "  1.64147051  1.1833431   0.49615198  0.49615198 -0.87823024 -1.10729395\n",
            " -1.10729395 -1.56542136 -0.19103913  1.64147051  0.95427939  0.26708828\n",
            "  0.26708828  0.26708828 -1.10729395 -0.42010283  1.4124068  -0.87823024\n",
            " -1.56542136 -1.10729395  0.95427939  1.4124068   0.95427939  0.49615198\n",
            "  1.64147051  0.49615198 -0.87823024 -1.10729395  1.64147051  0.95427939\n",
            " -0.42010283  1.1833431  -0.19103913  1.4124068  -0.42010283  1.1833431\n",
            "  0.49615198  0.49615198 -1.56542136 -0.87823024 -1.10729395  1.64147051\n",
            "  0.49615198  0.03802457  0.03802457  0.95427939  1.4124068   1.1833431\n",
            " -1.10729395 -0.64916654 -0.64916654  0.49615198 -1.33635765  1.1833431\n",
            "  0.49615198 -0.87823024  0.95427939  1.1833431  -1.10729395 -0.64916654\n",
            "  0.03802457 -0.64916654  1.1833431   0.72521569  0.72521569 -1.33635765\n",
            " -0.42010283 -1.10729395  0.95427939 -0.42010283 -0.64916654 -1.33635765\n",
            "  0.03802457  0.49615198  0.72521569 -1.10729395 -0.64916654  0.26708828\n",
            "  1.64147051 -0.87823024  0.03802457 -0.42010283 -1.56542136  0.26708828\n",
            "  0.95427939  0.26708828  1.4124068  -0.87823024  1.4124068  -0.42010283\n",
            "  1.4124068   0.03802457 -1.56542136 -0.64916654  1.1833431  -1.10729395\n",
            "  0.03802457 -1.56542136  0.03802457 -0.87823024 -0.42010283  1.64147051\n",
            "  1.64147051 -0.87823024  0.95427939 -0.87823024  0.26708828 -1.56542136\n",
            " -0.87823024 -0.42010283 -0.19103913 -0.64916654  1.64147051  0.72521569\n",
            " -1.33635765 -1.33635765  0.49615198 -0.19103913  1.64147051  0.03802457\n",
            " -0.19103913  1.1833431  -0.87823024  0.49615198 -1.33635765 -0.42010283\n",
            "  0.49615198  0.49615198  1.1833431  -0.42010283  0.72521569  0.03802457\n",
            "  1.1833431  -1.56542136  0.95427939  0.26708828 -1.56542136  0.49615198\n",
            " -0.19103913  0.72521569 -0.64916654 -0.87823024  0.49615198  1.1833431\n",
            "  1.64147051  1.4124068   0.26708828  1.4124068  -1.33635765  0.26708828\n",
            " -1.10729395  0.03802457  0.26708828 -0.64916654  1.4124068  -1.56542136\n",
            "  1.1833431   1.1833431  -0.87823024  1.4124068   1.4124068   1.1833431\n",
            " -0.42010283  1.4124068   0.72521569 -1.33635765 -0.87823024  0.03802457\n",
            "  0.26708828  1.1833431   0.03802457 -0.87823024  1.4124068  -0.64916654\n",
            " -1.33635765 -0.42010283  0.26708828 -1.56542136  1.4124068   1.1833431\n",
            "  0.95427939  1.64147051  1.1833431   0.03802457 -0.19103913 -0.87823024\n",
            " -0.87823024 -1.10729395 -1.10729395 -0.19103913 -0.87823024 -1.10729395\n",
            " -0.19103913 -0.87823024  0.72521569  0.72521569  1.1833431  -1.10729395\n",
            " -0.42010283 -0.64916654 -1.56542136  0.03802457 -0.64916654  0.26708828\n",
            " -1.33635765  1.1833431  -0.64916654 -1.56542136  0.03802457 -0.42010283\n",
            " -0.87823024 -0.19103913  1.1833431   1.64147051 -1.56542136  0.49615198\n",
            " -0.87823024  0.49615198  0.49615198  0.26708828 -1.10729395  0.95427939\n",
            " -1.10729395  1.4124068  -1.56542136  1.1833431  -1.10729395  0.03802457\n",
            "  1.4124068  -1.10729395 -0.87823024 -1.33635765 -0.64916654 -0.87823024\n",
            "  0.49615198 -0.19103913 -1.10729395  1.1833431   0.26708828  1.64147051\n",
            " -1.33635765 -1.33635765  0.26708828 -1.56542136 -0.42010283  0.95427939\n",
            "  0.49615198 -1.33635765 -0.87823024  1.1833431   0.95427939 -0.42010283\n",
            "  0.95427939 -1.56542136 -0.87823024  1.4124068   0.26708828  0.26708828\n",
            " -0.64916654  0.26708828 -0.64916654  1.4124068   0.72521569  1.64147051\n",
            " -1.56542136  0.49615198 -1.33635765 -1.33635765 -0.42010283 -0.64916654\n",
            "  0.49615198  0.95427939  0.03802457  1.4124068   0.95427939 -0.19103913\n",
            "  0.95427939  0.72521569 -1.10729395 -1.10729395 -0.64916654  0.03802457\n",
            "  0.03802457  0.26708828  0.49615198  0.03802457 -0.64916654 -1.10729395\n",
            " -1.56542136 -1.56542136 -1.33635765  0.72521569  1.4124068   0.26708828\n",
            " -0.87823024 -1.10729395 -0.64916654 -1.33635765  0.95427939  0.95427939\n",
            " -1.33635765  0.26708828  0.26708828  1.64147051  1.4124068   0.72521569\n",
            " -1.10729395  1.64147051  0.49615198  0.95427939  0.72521569  1.4124068\n",
            " -1.10729395  0.72521569 -1.56542136 -0.87823024  1.4124068  -0.64916654\n",
            "  0.26708828 -0.42010283 -1.10729395 -0.42010283 -1.56542136  0.95427939\n",
            "  1.1833431  -0.87823024 -1.56542136  0.72521569 -1.10729395  0.49615198\n",
            " -0.87823024 -1.56542136  0.26708828 -0.42010283 -0.42010283  1.64147051\n",
            " -0.42010283 -0.42010283  0.95427939 -1.56542136  1.64147051  1.64147051\n",
            " -0.87823024 -1.10729395 -1.10729395  1.1833431   1.1833431   0.26708828\n",
            " -1.10729395 -0.64916654 -1.10729395 -1.33635765 -0.64916654 -0.42010283\n",
            "  1.4124068  -0.87823024 -1.10729395 -1.10729395  1.64147051 -0.42010283\n",
            " -1.33635765 -1.33635765  1.1833431  -1.33635765  1.1833431   0.49615198\n",
            " -1.33635765 -0.19103913 -1.10729395  0.49615198  0.95427939 -0.19103913\n",
            "  0.26708828 -0.19103913 -1.10729395  1.1833431  -0.19103913 -0.64916654\n",
            "  1.64147051  0.49615198  1.4124068   0.26708828 -0.19103913  0.95427939\n",
            "  0.95427939  0.95427939]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.14153798 -1.14153798 -0.44462835 -0.44462835 -1.14153798 -1.14153798\n",
            " -1.14153798 -1.14153798 -1.14153798  0.25228129 -1.14153798  0.94919092\n",
            " -1.14153798 -1.14153798 -1.14153798 -0.44462835 -0.44462835 -0.44462835\n",
            " -1.14153798 -1.14153798 -0.44462835 -1.14153798 -1.14153798 -1.14153798\n",
            "  0.94919092  0.25228129 -1.14153798 -0.44462835  0.25228129 -1.14153798\n",
            " -1.14153798  0.25228129 -1.14153798 -1.14153798 -1.14153798  0.25228129\n",
            "  0.94919092  0.25228129 -1.14153798 -0.44462835 -0.44462835 -1.14153798\n",
            " -0.44462835 -1.14153798 -1.14153798 -1.14153798 -1.14153798 -1.14153798\n",
            " -1.14153798 -1.14153798 -0.44462835 -1.14153798 -1.14153798 -1.14153798\n",
            " -0.44462835 -1.14153798 -1.14153798 -0.44462835 -1.14153798 -1.14153798\n",
            " -1.14153798 -0.44462835 -1.14153798 -0.44462835 -1.14153798  0.25228129\n",
            " -0.44462835  0.94919092 -1.14153798 -0.44462835 -1.14153798 -1.14153798\n",
            " -1.14153798 -0.44462835  0.94919092 -0.44462835 -1.14153798 -1.14153798\n",
            " -0.44462835 -1.14153798 -1.14153798 -1.14153798 -1.14153798 -1.14153798\n",
            " -1.14153798 -1.14153798 -1.14153798  0.94919092 -1.14153798 -1.14153798\n",
            " -1.14153798 -1.14153798  0.25228129 -0.44462835 -1.14153798 -1.14153798\n",
            " -0.44462835  0.25228129 -1.14153798 -1.14153798 -0.44462835  1.64610055\n",
            " -0.44462835  0.94919092 -1.14153798  0.94919092 -0.44462835 -0.44462835\n",
            "  1.64610055  0.94919092  1.64610055 -1.14153798 -1.14153798  0.25228129\n",
            " -1.14153798  0.94919092  1.64610055  0.94919092  1.64610055 -0.44462835\n",
            " -1.14153798 -1.14153798  0.25228129 -1.14153798  0.25228129 -1.14153798\n",
            " -1.14153798  0.94919092  0.25228129  0.94919092 -0.44462835 -1.14153798\n",
            " -1.14153798  0.25228129  1.64610055  1.64610055 -1.14153798 -0.44462835\n",
            "  0.25228129 -0.44462835  1.64610055  0.94919092  1.64610055  1.64610055\n",
            "  1.64610055 -0.44462835 -0.44462835 -1.14153798  1.64610055  0.94919092\n",
            " -0.44462835  1.64610055  1.64610055  0.94919092 -1.14153798 -0.44462835\n",
            " -0.44462835  0.94919092  0.25228129 -1.14153798  0.94919092 -1.14153798\n",
            " -0.44462835 -1.14153798  0.25228129 -0.44462835  1.64610055  0.94919092\n",
            " -0.44462835  0.94919092 -1.14153798  1.64610055  0.94919092  0.25228129\n",
            "  0.94919092 -1.14153798  1.64610055  1.64610055  1.64610055 -1.14153798\n",
            "  0.25228129  1.64610055 -0.44462835  0.94919092 -0.44462835 -0.44462835\n",
            "  0.94919092 -1.14153798  0.25228129  0.25228129 -0.44462835  0.94919092\n",
            "  1.64610055 -0.44462835  0.25228129  0.25228129 -0.44462835  1.64610055\n",
            "  0.25228129 -1.14153798 -1.14153798  0.94919092 -1.14153798  0.94919092\n",
            "  1.64610055 -0.44462835 -1.14153798  0.94919092  0.25228129  0.25228129\n",
            "  0.25228129 -0.44462835 -0.44462835  1.64610055 -0.44462835  0.94919092\n",
            "  0.94919092  0.25228129 -0.44462835  0.94919092  0.25228129  0.25228129\n",
            " -1.14153798 -0.44462835  0.94919092 -1.14153798  1.64610055  0.25228129\n",
            " -1.14153798  0.25228129  0.25228129  1.64610055  1.64610055  0.25228129\n",
            " -0.44462835  0.94919092  1.64610055  0.94919092  0.25228129  0.25228129\n",
            "  0.94919092  1.64610055 -1.14153798  0.25228129  0.25228129 -1.14153798\n",
            "  0.25228129 -1.14153798  0.25228129 -1.14153798  1.64610055 -1.14153798\n",
            " -1.14153798 -0.44462835  0.25228129  1.64610055 -0.44462835 -1.14153798\n",
            "  0.94919092  1.64610055  0.94919092  1.64610055 -1.14153798  0.25228129\n",
            "  1.64610055  0.25228129 -1.14153798 -0.44462835  1.64610055  0.25228129\n",
            " -1.14153798 -0.44462835 -0.44462835  0.25228129 -0.44462835  0.94919092\n",
            " -1.14153798  1.64610055 -1.14153798 -0.44462835 -0.44462835  0.94919092\n",
            "  1.64610055  0.25228129  0.94919092  0.25228129 -1.14153798 -0.44462835\n",
            " -0.44462835 -1.14153798  0.94919092 -1.14153798 -0.44462835  0.25228129\n",
            "  0.94919092  0.25228129  1.64610055 -1.14153798  0.94919092  0.94919092\n",
            " -0.44462835  0.25228129 -0.44462835  1.64610055 -0.44462835  1.64610055\n",
            "  0.25228129  0.25228129  1.64610055  1.64610055 -1.14153798  0.94919092\n",
            "  0.94919092 -1.14153798 -0.44462835 -1.14153798 -1.14153798 -1.14153798\n",
            "  1.64610055 -1.14153798 -1.14153798 -1.14153798 -0.44462835  0.94919092\n",
            "  0.25228129  1.64610055  0.25228129  0.94919092  1.64610055  1.64610055\n",
            " -1.14153798 -1.14153798  0.25228129 -0.44462835  0.94919092  0.25228129\n",
            "  1.64610055  0.25228129  0.94919092 -1.14153798  0.94919092  0.94919092\n",
            " -1.14153798  1.64610055 -0.44462835  1.64610055 -0.44462835 -0.44462835\n",
            "  0.94919092  0.94919092 -0.44462835 -1.14153798 -1.14153798  0.94919092\n",
            "  1.64610055 -0.44462835  0.25228129  0.94919092 -0.44462835  1.64610055\n",
            " -0.44462835  1.64610055  1.64610055 -0.44462835  1.64610055 -1.14153798\n",
            " -1.14153798  1.64610055  0.25228129 -0.44462835 -0.44462835 -1.14153798\n",
            "  0.94919092  0.25228129  0.94919092 -1.14153798  0.25228129  0.25228129\n",
            "  0.25228129 -1.14153798  0.25228129 -1.14153798  0.94919092 -0.44462835\n",
            "  1.64610055 -1.14153798  1.64610055 -0.44462835 -0.44462835 -1.14153798\n",
            "  1.64610055 -1.14153798  1.64610055 -0.44462835  0.94919092 -1.14153798\n",
            " -1.14153798  1.64610055  0.25228129  0.25228129 -0.44462835  0.25228129\n",
            "  1.64610055 -0.44462835 -1.14153798 -0.44462835  0.94919092 -0.44462835\n",
            "  0.25228129  0.25228129 -1.14153798  0.25228129  0.25228129  0.25228129\n",
            "  0.94919092  0.25228129  0.94919092  0.94919092 -0.44462835 -1.14153798\n",
            " -1.14153798 -1.14153798 -1.14153798 -1.14153798 -0.44462835  0.25228129\n",
            "  0.25228129  0.94919092  0.94919092  0.94919092 -1.14153798  0.94919092\n",
            "  0.94919092  0.94919092  0.94919092  0.94919092 -1.14153798 -0.44462835\n",
            "  0.94919092  0.94919092 -1.14153798  0.25228129  0.94919092  0.94919092\n",
            " -1.14153798 -1.14153798 -0.44462835 -1.14153798  0.25228129 -0.44462835\n",
            "  0.94919092 -0.44462835 -1.14153798 -0.44462835  0.94919092  0.25228129\n",
            "  0.94919092  0.25228129 -0.44462835  1.64610055  1.64610055 -1.14153798\n",
            " -0.44462835  0.94919092  1.64610055 -1.14153798 -1.14153798  1.64610055\n",
            " -0.44462835  0.25228129 -0.44462835 -1.14153798  0.25228129  1.64610055\n",
            " -1.14153798 -0.44462835  1.64610055  0.94919092  1.64610055  0.94919092\n",
            "  0.25228129  1.64610055  1.64610055  0.94919092  0.94919092 -0.44462835\n",
            "  0.94919092 -0.44462835 -1.14153798  0.25228129 -0.44462835  0.25228129\n",
            " -1.14153798 -1.14153798  0.25228129 -1.14153798  1.64610055  0.94919092\n",
            "  0.25228129  1.64610055]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.45333121  0.97617201 -1.16808281  0.0827325   1.06551596  1.15485991\n",
            "  0.4401083  -0.00661145  0.35076435 -0.90005096  0.2614204  -0.98939491\n",
            " -1.16808281 -1.34677071 -0.0959554   1.60157966  1.69092361  0.7974841\n",
            "  0.70814015 -0.36398726  0.17207645 -0.0959554  -0.00661145  0.97617201\n",
            " -0.72136306  0.7974841   0.0827325   1.15485991 -0.72136306 -0.0959554\n",
            "  0.97617201 -0.81070701 -1.16808281  1.15485991  0.70814015 -1.16808281\n",
            "  0.35076435 -0.0959554   0.7974841   1.24420386 -0.18529935 -0.81070701\n",
            "  0.0827325   0.35076435 -0.63201911  0.52945225 -1.25742676  0.70814015\n",
            " -0.72136306 -0.45333121 -0.2746433   0.0827325  -0.72136306  0.4401083\n",
            "  0.17207645  1.24420386  0.17207645  1.33354781  1.42289176 -0.45333121\n",
            "  0.7974841   1.51223571 -0.72136306 -0.45333121  0.52945225  0.70814015\n",
            "  0.0827325  -0.36398726  1.42289176 -0.0959554  -0.00661145  0.52945225\n",
            "  1.06551596  0.35076435  1.51223571 -0.54267516  1.42289176  1.51223571\n",
            " -1.25742676  1.51223571  1.51223571 -0.2746433   1.24420386  1.51223571\n",
            " -0.2746433   0.88682805  0.52945225 -1.25742676  0.88682805 -0.0959554\n",
            "  1.60157966 -0.45333121 -1.16808281 -0.90005096 -0.63201911 -0.90005096\n",
            " -0.63201911  1.33354781  1.42289176 -0.36398726 -0.18529935 -1.70414652\n",
            "  0.0827325  -1.61480257 -0.63201911 -1.25742676  1.69092361  0.4401083\n",
            " -0.45333121  0.70814015  1.60157966  0.17207645  1.24420386 -1.07873886\n",
            "  0.97617201 -0.72136306 -1.34677071  0.35076435 -1.61480257  0.2614204\n",
            "  1.42289176 -0.18529935 -0.36398726 -1.07873886  1.33354781  1.69092361\n",
            "  0.17207645 -1.70414652 -0.45333121  1.24420386 -1.70414652 -0.63201911\n",
            " -0.81070701  0.52945225 -0.18529935 -1.34677071 -0.00661145 -1.61480257\n",
            " -1.70414652  1.24420386 -0.0959554   1.15485991  0.0827325   1.06551596\n",
            "  0.97617201  0.7974841   1.42289176  1.69092361 -1.61480257 -1.43611466\n",
            " -0.00661145  1.33354781 -1.52545861  1.24420386  1.06551596  1.24420386\n",
            " -1.25742676  0.35076435  1.24420386 -0.72136306  0.35076435 -0.18529935\n",
            " -0.45333121  1.60157966  0.17207645 -0.36398726  0.70814015  1.33354781\n",
            " -0.18529935 -1.16808281  0.35076435 -0.45333121 -0.2746433  -0.45333121\n",
            " -1.16808281  1.33354781  1.24420386 -1.43611466  0.4401083   1.24420386\n",
            "  0.17207645 -0.72136306  1.15485991 -1.43611466 -0.90005096  0.7974841\n",
            "  0.7974841  -0.98939491  0.17207645  0.52945225  0.6187962   0.4401083\n",
            " -0.36398726  0.6187962  -1.25742676 -0.54267516  0.35076435 -0.2746433\n",
            "  1.42289176  0.0827325  -1.61480257 -0.90005096 -1.70414652 -0.18529935\n",
            " -0.90005096 -1.43611466 -0.90005096 -0.63201911  1.42289176 -0.63201911\n",
            "  1.51223571 -0.63201911 -0.54267516  1.51223571 -0.98939491  0.2614204\n",
            " -0.81070701 -0.98939491 -0.72136306 -1.43611466  0.70814015  1.69092361\n",
            "  0.4401083  -1.25742676 -1.34677071 -1.25742676  1.69092361  0.97617201\n",
            " -0.63201911 -1.52545861  1.15485991 -1.16808281 -1.61480257 -0.45333121\n",
            " -1.25742676 -0.2746433   1.42289176  0.2614204  -0.36398726 -1.52545861\n",
            "  1.51223571  0.52945225  0.4401083  -1.79349047  1.33354781  1.33354781\n",
            "  1.15485991  1.69092361  0.7974841  -0.81070701 -0.45333121  0.4401083\n",
            " -1.16808281  1.60157966  1.69092361  0.0827325   0.7974841   0.70814015\n",
            " -1.43611466  0.35076435 -0.81070701  1.15485991  0.4401083  -0.0959554\n",
            "  0.35076435  0.6187962  -1.43611466 -0.2746433  -1.61480257 -0.45333121\n",
            "  1.33354781  0.88682805 -0.63201911 -0.36398726  0.97617201 -0.0959554\n",
            " -0.98939491 -0.81070701 -1.34677071  0.70814015 -0.63201911  0.70814015\n",
            " -1.61480257  0.35076435  0.35076435  0.70814015 -0.0959554   0.2614204\n",
            "  0.88682805 -1.16808281 -0.0959554  -0.72136306 -0.54267516 -1.34677071\n",
            " -1.25742676 -0.63201911  0.97617201 -1.61480257  0.7974841  -0.0959554\n",
            "  1.15485991 -0.81070701 -1.16808281 -1.43611466  1.60157966 -1.43611466\n",
            " -0.98939491 -0.81070701  1.42289176 -0.0959554   1.24420386 -0.0959554\n",
            "  0.17207645 -1.16808281 -0.98939491 -1.52545861  0.4401083  -0.72136306\n",
            "  1.51223571  0.17207645 -0.81070701  0.97617201 -1.70414652  0.70814015\n",
            "  0.17207645 -0.54267516  1.15485991  1.24420386 -1.52545861  0.88682805\n",
            " -0.72136306 -0.54267516  1.42289176 -0.18529935  1.15485991 -0.98939491\n",
            " -0.2746433  -1.52545861 -1.61480257 -1.70414652 -1.61480257  1.33354781\n",
            " -0.45333121 -0.0959554  -1.16808281 -0.63201911  0.52945225 -1.34677071\n",
            "  1.51223571 -0.63201911 -0.63201911  1.33354781 -0.72136306 -0.81070701\n",
            " -1.34677071  0.35076435 -0.00661145 -1.52545861  1.42289176  0.0827325\n",
            "  1.60157966  0.97617201  0.4401083  -0.00661145  1.06551596 -0.54267516\n",
            "  0.17207645  0.2614204  -1.25742676  1.51223571 -0.54267516 -0.98939491\n",
            "  1.15485991 -0.63201911  0.97617201 -0.81070701  0.35076435  0.17207645\n",
            " -0.18529935 -1.43611466  0.35076435 -0.72136306 -0.36398726 -1.52545861\n",
            "  1.51223571 -0.0959554  -0.45333121 -0.18529935  1.51223571 -0.2746433\n",
            "  1.06551596  0.4401083   0.7974841  -1.43611466 -1.34677071  1.33354781\n",
            "  1.33354781 -1.34677071 -0.00661145 -0.0959554  -0.00661145  0.35076435\n",
            "  1.15485991 -1.34677071 -1.70414652  1.24420386  0.0827325   0.6187962\n",
            " -1.34677071 -0.81070701 -0.54267516 -1.61480257  1.42289176 -0.45333121\n",
            "  0.6187962   1.06551596  1.51223571 -1.07873886 -0.00661145  0.17207645\n",
            " -0.0959554  -0.0959554   1.51223571  1.60157966  1.51223571 -0.0959554\n",
            " -1.61480257 -0.18529935  0.35076435 -1.16808281  0.7974841   1.42289176\n",
            "  1.24420386 -0.54267516  0.70814015 -1.61480257 -0.2746433  -1.79349047\n",
            " -0.72136306  1.06551596 -0.36398726 -0.90005096 -1.16808281 -1.43611466\n",
            "  1.33354781 -0.81070701 -1.70414652  1.60157966 -0.45333121  1.42289176\n",
            " -0.00661145  0.7974841   0.17207645  0.6187962  -0.18529935 -0.90005096\n",
            "  1.51223571 -1.52545861 -1.34677071  1.42289176 -0.36398726 -0.72136306\n",
            "  1.15485991 -0.90005096  1.15485991  0.2614204   1.42289176 -0.81070701\n",
            " -0.81070701  1.06551596 -0.36398726 -1.16808281 -1.43611466  0.0827325\n",
            "  0.2614204   1.69092361 -1.07873886  0.7974841  -0.18529935 -0.45333121\n",
            " -1.16808281  1.60157966 -0.18529935 -1.16808281  0.2614204  -0.81070701\n",
            " -0.54267516 -1.16808281  0.52945225 -1.34677071  0.70814015 -0.72136306\n",
            "  0.7974841   1.42289176 -1.25742676  1.51223571  1.15485991 -0.00661145\n",
            "  1.24420386 -0.98939491]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n",
            "<ipython-input-11-973820273b74>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.64227837e+00  3.50645501e-01 -1.61758770e+00 -1.32930190e-02\n",
            " -7.86334583e-01 -1.40136805e+00 -1.53596623e+00 -1.05719307e+00\n",
            "  6.97512278e-01 -1.78397652e-01  1.59204925e+00 -1.27393199e+00\n",
            "  4.20986979e-02  3.21764045e-01 -5.49277259e-01 -9.34379700e-01\n",
            " -7.18321278e-01 -4.26786766e-01  2.43362503e-01 -1.24894234e-01\n",
            "  1.65109006e+00 -1.19524871e+00 -1.87368065e-01  8.18844841e-01\n",
            "  1.09299317e+00 -1.01143170e+00 -1.66900227e+00  9.92059026e-01\n",
            " -1.54228803e+00  4.55425623e-01  5.84222694e-02 -1.57535095e+00\n",
            "  1.56128709e+00 -1.44503555e+00 -1.16353486e+00 -6.69623300e-01\n",
            "  9.85347147e-01 -1.19875230e+00 -1.44214692e+00  1.06480663e+00\n",
            "  8.21706177e-01  1.35321101e+00 -1.41126900e+00  8.07033343e-01\n",
            "  1.33117674e-01  1.56557189e-02 -5.63135870e-01  7.59757122e-01\n",
            "  1.59785894e+00 -1.64707285e+00 -5.34889897e-01  1.45213748e+00\n",
            " -6.82322949e-01  1.21265004e-02 -1.27578066e+00  1.19626232e+00\n",
            "  4.68703393e-01  1.19448701e+00 -1.32496359e+00  3.08312378e-02\n",
            " -2.20278395e-01  1.23406996e+00  1.29198569e+00  1.28992005e+00\n",
            " -1.36668386e+00 -1.25580574e+00 -9.80481391e-01  9.78048584e-01\n",
            " -1.62762168e+00 -8.08351270e-01 -7.27644245e-01  9.57985965e-01\n",
            "  4.52772511e-01  8.73990547e-01 -1.47011689e+00 -3.03504625e-02\n",
            " -2.15436343e-01 -1.05537529e+00  1.03281019e+00 -1.00733377e+00\n",
            " -6.19049967e-01 -6.31513621e-01  1.79279017e-01  6.59435558e-01\n",
            "  9.05421325e-01  1.33458268e+00 -9.01725207e-01  1.14771988e+00\n",
            "  1.09128382e+00 -5.29731063e-01 -1.61825393e+00 -1.52383458e+00\n",
            " -1.42755840e+00  2.87563636e-01  5.95327719e-01  6.54764168e-01\n",
            " -1.32684065e+00 -1.59828350e+00 -1.44018268e+00  1.61354676e+00\n",
            " -8.82843002e-01 -8.95148373e-01  3.51326389e-01 -1.37772877e-02\n",
            " -6.92907371e-01 -2.27657816e-01 -1.35566072e+00  8.31329811e-01\n",
            " -1.12641258e+00 -1.37511692e+00  7.94225783e-01  9.28058371e-01\n",
            "  1.21227222e+00 -1.46781131e+00  1.54493458e+00 -9.00947027e-01\n",
            " -5.93848838e-01  8.07276593e-01 -8.08630618e-01 -1.20186403e+00\n",
            " -1.26489685e+00  6.55771455e-01  1.57684519e+00  7.76629403e-01\n",
            " -7.04538651e-01  7.51086563e-01  4.57007687e-01  9.31554069e-01\n",
            " -2.02602643e-01 -1.00850151e-01  7.98329929e-01  1.37871342e-01\n",
            " -1.19859712e+00  6.27875129e-01 -8.36114080e-01  1.65729167e+00\n",
            "  1.05536026e-01 -1.18985960e+00 -7.58340389e-01 -8.09152623e-01\n",
            "  4.49955890e-01  2.79899922e-01 -1.04017065e+00  1.08588324e+00\n",
            "  1.56653061e+00 -1.34772441e+00 -6.89321862e-01  9.90040470e-01\n",
            "  3.56206511e-01 -7.57574665e-01  3.73656751e-01  7.52548577e-01\n",
            " -8.35319129e-01  1.36778866e+00  1.60433466e-01  4.40931974e-01\n",
            " -5.03709918e-01 -4.95508614e-01  3.40883822e-01  1.42248007e+00\n",
            "  3.48455479e-01  1.51078473e+00  1.47655244e+00  1.54384042e+00\n",
            "  7.13341673e-01 -8.57347673e-02 -9.78937886e-02  6.69172436e-01\n",
            " -1.09696453e-03 -1.66220702e+00  1.22704607e+00  1.38200876e+00\n",
            " -1.35790597e+00  6.01216777e-01 -1.26233594e+00 -1.57107644e+00\n",
            " -1.23998026e+00 -4.75942102e-01  1.23213293e+00  2.07689026e-01\n",
            "  8.47569815e-01 -1.26478274e-02 -5.35211364e-01  1.06408993e+00\n",
            " -1.30868139e+00 -1.58500646e+00  1.06972692e+00  1.10054062e+00\n",
            " -1.00755800e-01  1.13654009e+00 -2.22330016e-01 -4.89976739e-01\n",
            " -8.71981790e-01 -7.44656195e-01 -1.43940570e+00 -3.27213477e-01\n",
            " -2.44648969e-02 -1.79026247e-01  1.70137189e+00  1.90107744e-01\n",
            " -5.97238628e-01 -3.43642484e-01  1.15607660e+00 -6.36954878e-01\n",
            " -1.49504050e+00 -1.55039517e+00 -1.28059891e+00  9.67679504e-01\n",
            " -2.46826030e-01 -1.19833616e+00 -9.45946463e-01  1.49922765e+00\n",
            " -3.32361396e-01 -5.57616109e-01 -3.47300829e-01  8.21526454e-01\n",
            " -1.59625917e+00  1.46475619e+00  1.24587273e+00 -1.44880128e+00\n",
            " -1.21712243e+00  2.28640256e-01  7.46273136e-01  9.55517648e-02\n",
            " -4.32879713e-01 -2.78967852e-02  1.52265048e-01 -6.50676044e-01\n",
            " -1.50281120e+00  1.25031793e+00  2.30250217e-01  1.32750514e+00\n",
            " -1.06099254e+00 -1.63513310e-01  1.68426137e+00 -5.18581701e-01\n",
            "  9.51380610e-01 -7.94667338e-01  7.24654699e-01  1.71206385e+00\n",
            "  6.81787146e-01  1.23503140e+00 -4.94294883e-01 -1.46221556e+00\n",
            "  7.79206862e-02  1.70321629e+00 -1.36958402e-02 -1.52453257e+00\n",
            "  1.60730019e+00  1.39810757e+00 -6.71800400e-01 -7.86241793e-01\n",
            " -5.75130603e-01  8.85367924e-01  3.89622057e-01 -1.50140845e+00\n",
            " -9.88765584e-01 -3.60873313e-01 -7.26866055e-01  1.36847898e-02\n",
            " -1.65615475e-01  2.77927762e-01 -9.81701325e-01 -1.34606918e+00\n",
            "  1.62009932e+00  4.80870485e-01 -1.49341342e+00 -3.75063623e-01\n",
            "  9.42259006e-01 -1.36903206e+00 -1.60366993e-01 -1.45798513e+00\n",
            " -1.29619984e+00 -5.05165089e-01 -3.40991554e-01  6.52260719e-01\n",
            "  1.23485833e+00 -1.65313846e+00 -5.98570799e-01 -7.02079262e-02\n",
            "  3.50843913e-01  4.99997550e-01 -1.27035210e+00  7.95792063e-01\n",
            " -1.26204702e-01  1.01711852e-01  1.25395919e+00  1.17708202e+00\n",
            " -6.68617051e-02  2.78180641e-01  9.04313874e-01 -1.41264209e+00\n",
            " -8.85834174e-01  6.25769151e-01 -1.34666338e+00  9.12722439e-01\n",
            "  8.76937581e-01  1.17096472e+00  1.49117265e+00  6.94033104e-01\n",
            " -2.63736144e-01  1.13122826e+00  9.05735752e-01  8.94131711e-01\n",
            "  9.28279232e-01 -4.52060428e-01 -3.31099624e-01 -2.74493783e-01\n",
            "  1.66240605e-01 -3.26540644e-01 -8.29686900e-01 -1.16515420e+00\n",
            "  4.98859650e-01 -1.41571025e+00 -1.93048050e-02 -3.75316970e-01\n",
            " -1.24259539e+00  1.64862074e+00 -2.75419343e-01 -1.67096261e-01\n",
            "  3.23478841e-01  2.67636228e-01 -1.04030608e+00 -1.55165172e+00\n",
            "  1.70890244e+00 -4.46322557e-01 -5.56404281e-01 -1.17155863e+00\n",
            "  8.73772888e-01  1.57190065e+00 -5.12376972e-01  7.27402818e-01\n",
            " -1.33712791e+00 -1.59691677e+00 -1.00780167e+00 -1.13273737e+00\n",
            " -1.39991263e+00  8.36568141e-01  1.70290980e+00 -2.74256883e-01\n",
            "  1.06838711e+00  1.06088672e+00  1.34700797e+00 -7.68635895e-01\n",
            " -3.13409093e-01 -2.61218619e-01  7.04216521e-01  3.54103686e-02\n",
            " -6.68714932e-01 -5.97932557e-01  1.41964090e+00  1.06268681e+00\n",
            "  1.60023897e+00 -5.21014807e-01  4.41050155e-01  2.83739944e-01\n",
            " -1.31198461e+00 -3.62330822e-01 -3.03319379e-01  6.39075100e-02\n",
            " -1.27013895e+00  1.67771843e+00  1.65707295e+00 -1.15260798e-01\n",
            "  1.32460096e+00  8.84855117e-01  1.71488891e+00  7.57305765e-01\n",
            "  1.08941365e+00  1.27387602e+00  1.36511454e+00 -1.27009892e+00\n",
            "  1.35004808e+00 -1.52005141e+00 -2.58109514e-01  1.42865735e+00\n",
            "  3.89230619e-01 -7.03899899e-01  1.05603410e+00  1.38019809e+00\n",
            " -1.05959785e-01  5.17311237e-01 -1.35182520e+00 -8.02478635e-01\n",
            " -5.94862606e-01  2.98441796e-01  3.73698114e-01  6.82195583e-01\n",
            "  1.35109830e+00 -1.23599926e+00  5.91362959e-01 -9.61395318e-01\n",
            " -2.40100838e-02  1.41768401e+00  1.48654965e+00  7.28413235e-01\n",
            "  7.60878777e-01 -1.45948800e+00 -1.31007158e+00  1.33301306e+00\n",
            " -1.00030767e+00 -1.60909420e+00  5.26481113e-01  6.14783187e-01\n",
            " -9.43142191e-01  2.40287549e-01  1.14282562e+00 -1.78746078e-01\n",
            " -1.62521071e-01 -1.32097836e+00 -7.18285848e-01 -9.45516151e-01\n",
            "  1.19396139e+00 -8.54496810e-01  1.55095766e+00 -2.75627349e-01\n",
            " -1.41074477e+00  1.53848076e+00  1.13684850e+00 -1.49174122e+00\n",
            "  8.03169564e-01 -3.37628116e-01  4.39620592e-01 -1.31824358e-01\n",
            "  7.18406601e-02  4.43178073e-01  1.52187904e+00  5.48793162e-01\n",
            "  7.58450660e-01 -1.30746782e+00 -1.56204903e+00  9.07649041e-02\n",
            " -6.30664768e-01  1.57334954e+00  2.20171686e-01  9.00782683e-01\n",
            "  9.99376547e-01  8.87686670e-01  1.37378878e+00  8.30337552e-01\n",
            "  1.50485108e+00  4.58811504e-01  9.03949672e-01 -7.64171694e-01\n",
            "  1.51967350e+00  1.18042669e+00 -1.33586794e+00  2.54269505e-01\n",
            " -3.56129771e-01  2.75886511e-01 -1.07469913e+00  1.36602594e+00\n",
            " -6.39105026e-01  1.19849903e-02  1.02587685e+00 -4.04237008e-01\n",
            " -4.82338416e-01 -4.47776939e-01 -2.28816814e-01 -9.87040397e-01\n",
            " -1.11474492e+00 -1.60797601e+00 -1.06170480e+00 -6.09441488e-01\n",
            "  1.72181904e+00  1.31323135e+00  2.35377619e-01 -5.48352381e-01\n",
            " -1.69837161e-01  8.52309503e-01 -1.08588927e+00  1.51770107e+00\n",
            " -8.57783013e-04  1.56029133e-02 -2.37153441e-01 -1.35461746e+00\n",
            "  4.01118249e-01  1.63398345e+00 -1.25624394e-02 -1.55625184e+00\n",
            "  1.08165779e+00 -1.24048550e+00 -7.30990055e-01  6.23108416e-01\n",
            " -5.52890125e-01  1.72185476e+00  3.62937155e-01  5.11060969e-01\n",
            "  2.51600768e-01  1.72687804e+00 -5.41012114e-01 -6.31386132e-01\n",
            "  3.41424336e-01 -1.58486023e+00  1.33377271e+00 -8.63755046e-01\n",
            " -1.27430521e+00  2.79901098e-01  1.21114152e+00 -1.04003351e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  X_encoded.loc[:, X_encoded.select_dtypes(include=['float64', 'int64']).columns] = scaler.fit_transform(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the data into training and testing sets and then use, for example, a Random Forest Classifier for prediction"
      ],
      "metadata": {
        "id": "GYa-z2s2fLMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zyyI1IypdCes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8dbJutokdNQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have risk scores for each student, you could design an intervention service. For instance:\n",
        "\n",
        "A simple (rule-based) recommendation engine might look like this:"
      ],
      "metadata": {
        "id": "Vc22qCe8es4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_intervention(row):\n",
        "    if row['Attendance (%)'] < 60 and row['Total Marks'] < 50:\n",
        "        return \"Provide academic tutoring and counseling.\"\n",
        "    elif row.get('Disciplinary Records', 0) > 0:\n",
        "        return \"Signpost to behavioral intervention programs.\"\n",
        "    elif row.get('Digital Learning Hours', 0) < 5:\n",
        "        return \"Offer extra digital learning support.\"\n",
        "    else:\n",
        "        return \"Monitor and encourage engagement.\"\n",
        "\n",
        "# For the test set (or the entire dataset) add recommendations:\n",
        "df['Intervention'] = df.apply(recommend_intervention, axis=1)\n",
        "print(df[['Attendance (%)', 'Total Marks', 'Digital Learning Hours', 'Disciplinary Records', 'Intervention']].head())"
      ],
      "metadata": {
        "id": "Gf9fEKfxdNzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b835e513-e52a-4531-d665-4911d0ce0984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Attendance (%)  Total Marks  Digital Learning Hours  Disciplinary Records  \\\n",
            "0           56.22           67                       8                     0   \n",
            "1           96.55           51                       1                     0   \n",
            "2           81.24           80                       7                     1   \n",
            "3           71.91           61                       7                     1   \n",
            "4           40.92           43                       6                     0   \n",
            "\n",
            "                                    Intervention  \n",
            "0              Monitor and encourage engagement.  \n",
            "1          Offer extra digital learning support.  \n",
            "2  Signpost to behavioral intervention programs.  \n",
            "3  Signpost to behavioral intervention programs.  \n",
            "4      Provide academic tutoring and counseling.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a dataset with diverse academic, demographic, and behavioral features as you have, starting with a tree-based ensemble method such as Random Forest or XGBoost is a solid choice. These algorithms are robust in handling missing values, unscaled data, and feature interactions, and they provide feature importance metrics which are valuable in an educational context for interpreting which factors most influence dropout risk.\n"
      ],
      "metadata": {
        "id": "NoQEfdG9fR6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Classifiers ---\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "\n",
        "# ---------------------------\n",
        "# Define the Classifiers to Compare\n",
        "# ---------------------------\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"Gaussian NB\": GaussianNB(),\n",
        "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Compare Models Using Cross-Validation\n",
        "# ---------------------------\n",
        "# We will use 5-fold Stratified CV and compute accuracy, ROC-AUC, and F1-score.\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc',\n",
        "    'f1': 'f1'\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results = cross_validate(model, X_encoded, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "    results[name] = {\n",
        "        'accuracy': np.mean(cv_results['test_accuracy']),\n",
        "        'roc_auc': np.mean(cv_results['test_roc_auc']),\n",
        "        'f1': np.mean(cv_results['test_f1'])\n",
        "    }\n",
        "    print(f\"{name} results:\")\n",
        "    print(f\"  Accuracy: {results[name]['accuracy']:.3f}\")\n",
        "    print(f\"  ROC AUC : {results[name]['roc_auc']:.3f}\")\n",
        "    print(f\"  F1 Score: {results[name]['f1']:.3f}\\n\")\n",
        "\n",
        "# Optionally, display the comparison in a DataFrame:\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Comparison of Model Performance:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "lbiq53PnksPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fb7581-8d41-41a1-d7b5-1ce4d04b56ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression results:\n",
            "  Accuracy: 0.962\n",
            "  ROC AUC : 0.996\n",
            "  F1 Score: 0.902\n",
            "\n",
            "Random Forest results:\n",
            "  Accuracy: 0.926\n",
            "  ROC AUC : 1.000\n",
            "  F1 Score: 0.774\n",
            "\n",
            "SVM results:\n",
            "  Accuracy: 0.944\n",
            "  ROC AUC : 0.992\n",
            "  F1 Score: 0.836\n",
            "\n",
            "Gradient Boosting results:\n",
            "  Accuracy: 1.000\n",
            "  ROC AUC : 1.000\n",
            "  F1 Score: 1.000\n",
            "\n",
            "Gaussian NB results:\n",
            "  Accuracy: 0.264\n",
            "  ROC AUC : 0.525\n",
            "  F1 Score: 0.355\n",
            "\n",
            "XGBoost results:\n",
            "  Accuracy: 0.996\n",
            "  ROC AUC : 0.999\n",
            "  F1 Score: 0.990\n",
            "\n",
            "Comparison of Model Performance:\n",
            "                     accuracy   roc_auc        f1\n",
            "Logistic Regression     0.962  0.995683  0.901754\n",
            "Random Forest           0.926  0.999629  0.774126\n",
            "SVM                     0.944  0.992486  0.836422\n",
            "Gradient Boosting       1.000  1.000000  1.000000\n",
            "Gaussian NB             0.264  0.524876  0.354526\n",
            "XGBoost                 0.996  0.998614  0.990471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "SBhpg461Bg98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Gradient Boosting Model\n",
        "# ---------------------------\n",
        "# Define the classifier with hyperparameters:\n",
        "# n_estimators: number of weak learners (trees)\n",
        "# learning_rate: step size (shrinkage) for each tree's contribution\n",
        "# max_depth: maximum depth of each individual tree\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
        "                                 max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Model Evaluation\n",
        "# ---------------------------\n",
        "# Predict on the test set\n",
        "y_pred = gbc.predict(X_test)\n",
        "y_pred_proba = gbc.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Print out the classification report and ROC AUC Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ROC AUC Score: {:.3f}\".format(roc_auc_score(y_test, y_pred_proba)))"
      ],
      "metadata": {
        "id": "4riiuBrYmLzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18546fa0-060a-4511-b1ee-1515c2012d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        73\n",
            "           1       1.00      1.00      1.00        27\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "ROC AUC Score: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rL84uf3foOPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "2IOzatEgcMNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ---------------------------\n",
        "# Train the XGBoost Model\n",
        "# ---------------------------\n",
        "# We disable the label encoder and set eval_metric to logloss\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# Model Evaluation\n",
        "# ---------------------------\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC Score: {:.3f}\".format(roc_auc_score(y_test, y_pred_proba)))"
      ],
      "metadata": {
        "id": "H597zxt4w2Eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a04aab4-3ae9-4dbc-b5cc-b603c0f3525d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:38:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        73\n",
            "           1       0.90      1.00      0.95        27\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.95      0.98      0.96       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n",
            "ROC AUC Score: 0.979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Combine User Details with Predictions\n",
        "# ---------------------------\n",
        "# Since the train/test split retains the original indices, we can use these indices to retrieve user details.\n",
        "# Let's assume that user_details was created from the original data.\n",
        "results_df = df.loc[X_test.index].copy()\n",
        "results_df[\"Actual_Risk\"] = y_test\n",
        "results_df[\"Predicted_Risk\"] = y_pred\n",
        "\n",
        "# Optionally, if you wish to see probability information as well, add:\n",
        "results_df[\"Predicted_Prob\"] = y_pred_proba\n",
        "\n",
        "print(\"\\nOutput with User Details and Predictions:\")\n",
        "\n",
        "cols_to_drop = ['Internal Marks', 'External Marks', 'Total Marks','Class','Parent Education Level','Student ID.1',\n",
        "                'Religion/Caste',  'District','Toilet Facilities','Library','Student-Teacher Ratio',' Student-Teacher Ratio','Section','Electricity','Family Income Range','School Name']\n",
        "results_df = results_df.drop(columns=cols_to_drop, errors='ignore')\n",
        "print(results_df)\n",
        "# Optionally, save the results to an Excel or CSV file.\n",
        "# results_df.to_excel(\"dropout_predictions.xlsx\", index=False)\n",
        "# results_df.to_csv(\"dropout_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "bW2KLrIYoPGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a242c0-23e6-436d-9d8e-1ab91e5f8201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output with User Details and Predictions:\n",
            "    Student ID        Student Name  Attendance (%) Grade  Gender  Age  \\\n",
            "361       S362       Leslie Peters           52.01     B  Female   14   \n",
            "73        S074         Vivaan Shah           87.08     A  Female   11   \n",
            "374       S375     Amber Velazquez          100.00     B  Female   13   \n",
            "155       S156        Colleen Paul           57.83     B  Female   13   \n",
            "104       S105        James Becker           81.26     B    Male   11   \n",
            "..         ...                 ...             ...   ...     ...  ...   \n",
            "347       S348        Jeffrey Best           75.90     C    Male   11   \n",
            "86        S087   Inaaya  Chowdhury           81.07     B    Male   10   \n",
            "75        S076         Seher Gupta           81.03     B    Male   12   \n",
            "438       S439  Mr. Tanner Beltran           53.78     B  Female   12   \n",
            "15        S016            Azad Som           42.84     B    Male   13   \n",
            "\n",
            "    BPL Status DIKSHA Access  Digital Learning Hours Participation in Quiz  \\\n",
            "361        Yes           Yes                       1                    No   \n",
            "73         Yes            No                      14                    No   \n",
            "374        Yes           Yes                       4                    No   \n",
            "155        Yes            No                      14                    No   \n",
            "104         No            No                       3                   Yes   \n",
            "..         ...           ...                     ...                   ...   \n",
            "347         No            No                       3                    No   \n",
            "86         Yes           Yes                       2                   Yes   \n",
            "75          No            No                       7                   Yes   \n",
            "438        Yes            No                      12                   Yes   \n",
            "15          No            No                       8                   Yes   \n",
            "\n",
            "     ...  Disciplinary Records  Guardian Contact  Preferred Mode  \\\n",
            "361  ...                     4        9977487986             SMS   \n",
            "73   ...                     1        9744355286        WhatsApp   \n",
            "374  ...                     3        9415973568        WhatsApp   \n",
            "155  ...                     1        9618740490             SMS   \n",
            "104  ...                     0        9289854268             SMS   \n",
            "..   ...                   ...               ...             ...   \n",
            "347  ...                     1        9501113183        WhatsApp   \n",
            "86   ...                     0        9229283686        WhatsApp   \n",
            "75   ...                     1        9482038319             SMS   \n",
            "438  ...                     3        9889328868             SMS   \n",
            "15   ...                     1        9219811786             SMS   \n",
            "\n",
            "          Father Name      Mother Name Class-Section             Teacher  \\\n",
            "361    Steven Goodwin    Kelly Marquez     Class 8-A       J.Shiva Reddy   \n",
            "73           Heer Lad   Arnav Dâ€™Alia     Class 2-A   P.Bhargahav Kumar   \n",
            "374    Hayden Jackson   Melinda Cannon     Class 8-A       J.Shiva Reddy   \n",
            "155      Harold Riley   Destiny Thomas     Class 4-A   A.Sailaja Kondeti   \n",
            "104  Dr. Edwin Kelley      Mary Miller     Class 3-A       G.Damodar Rao   \n",
            "..                ...              ...           ...                 ...   \n",
            "347     John Robinson       Karen Gray     Class 7-B     C.Hanumatha Rao   \n",
            "86      Keya Bhargava       Kabir Gade     Class 2-B        V.Kasi Reddy   \n",
            "75      Kanav Ganguly       Umang Gaba     Class 2-B        V.Kasi Reddy   \n",
            "438     Kenneth Chase  Deborah Johnson     Class 9-B          L.Ramadevi   \n",
            "15       Umang Thaman  Jiya Brahmbhatt     Class 1-A  T.Sri Venkateshwar   \n",
            "\n",
            "    Actual_Risk  Predicted_Risk  Predicted_Prob  \n",
            "361           1               1        0.987776  \n",
            "73            0               0        0.002889  \n",
            "374           0               0        0.002889  \n",
            "155           1               1        0.987776  \n",
            "104           0               0        0.002889  \n",
            "..          ...             ...             ...  \n",
            "347           0               0        0.002889  \n",
            "86            0               0        0.002889  \n",
            "75            0               0        0.002889  \n",
            "438           1               1        0.987776  \n",
            "15            1               1        0.987776  \n",
            "\n",
            "[100 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load Your Data (Assuming you already have 'df' loaded)\n",
        "# ---------------------------\n",
        "\n",
        "print(\"Original Data (sample):\")\n",
        "print(df.head())\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Data Cleaning and Preprocessing\n",
        "# ---------------------------\n",
        "# (a) Drop non-predictive or personal information columns.\n",
        "# (b) Fill missing values:\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=[object]).columns.tolist()\n",
        "df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
        "df[cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
        "\n",
        "# (c) (Optional) If your training also created a target column, ignore or drop it:\n",
        "if 'Dropout_Risk' in df.columns:\n",
        "    data_clean = df.drop(columns=['Dropout_Risk'])\n",
        "    y = df['Dropout_Risk'] # Extract the target variable\n",
        "else:\n",
        "    # If 'Dropout_Risk' is not in df, you'll need to define 'y' based on your logic\n",
        "    # For example, if you're using attendance as a proxy:\n",
        "    y = np.where(df['Attendance (%)'] < 60, 1, 0)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Feature Engineering: One-Hot Encoding & Scaling\n",
        "# ---------------------------\n",
        "# One-Hot Encode categorical variables.\n",
        "X_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Initialize the StandardScaler and OneHotEncoder\n",
        "scaler = StandardScaler()\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # sparse=False for compatibility with older versions of scikit-learn\n",
        "\n",
        "# Identify numeric and categorical features\n",
        "numeric_features = X_encoded.select_dtypes(include=[np.number]).columns\n",
        "categorical_features = X_encoded.select_dtypes(include=[object]).columns\n",
        "\n",
        "# Fit and transform numeric features\n",
        "X_encoded[numeric_features] = scaler.fit_transform(X_encoded[numeric_features])\n",
        "\n",
        "# Save the scaler for later use\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# ---------------------------\n",
        "# 4. (Re-)Train and Save the Model\n",
        "# ---------------------------\n",
        "# Assuming you want to use XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_encoded, y) # Fit the model to your entire preprocessed dataset\n",
        "\n",
        "# Save the trained model to a file using joblib.dump\n",
        "joblib.dump(model, \"dropout_model.pkl\")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Load the Trained Model\n",
        "# ---------------------------\n",
        "# (Now this should work without errors)\n",
        "model = joblib.load(\"dropout_model.pkl\")\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Generate Predictions for the Entire Dataset\n",
        "# ---------------------------\n",
        "df[\"Predicted_Risk\"] = model.predict(X_encoded)\n",
        "df[\"Predicted_Probability\"] = model.predict_proba(X_encoded)[:, 1]\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Output the Results\n",
        "# ---------------------------\n",
        "print(\"\\nData with Predictions:\")\n",
        "print(df.head())\n",
        "\n",
        "df.to_excel(\"student_predictions.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0SyIC7MeUn4",
        "outputId": "38905df6-c0d6-4891-ba69-197228cb7a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data (sample):\n",
            "  Student ID        Student Name Student ID.1  Attendance (%)  Internal Marks  \\\n",
            "0       S001       Himmat Sehgal         S001           56.22              16   \n",
            "1       S002      Reyansh Tailor         S002           96.55              26   \n",
            "2       S003           Tanya Ben         S003           81.24              29   \n",
            "3       S004        Yasmin Reddy         S004           71.91              38   \n",
            "4       S005  Dharmajan Dhaliwal         S005           40.92              13   \n",
            "\n",
            "   External Marks  Total Marks Grade  Gender  Age  ... Toilet Facilities  \\\n",
            "0              51           67     B    Male   12  ...               Yes   \n",
            "1              25           51     C  Female   11  ...               Yes   \n",
            "2              51           80     B    Male   12  ...               Yes   \n",
            "3              23           61     B  Female   11  ...               Yes   \n",
            "4              30           43     C  Female   10  ...               Yes   \n",
            "\n",
            "  Library Guardian Contact Preferred Mode           Father Name  \\\n",
            "0     Yes       9014475712       WhatsApp          Akarsh Borra   \n",
            "1      No       9592551615            SMS             Baiju Din   \n",
            "2      No       9021637593            SMS            Rania Seth   \n",
            "3      No       9486986073            SMS    Pranay Subramanian   \n",
            "4      No       9262754377            SMS  Uthkarsh Chakraborty   \n",
            "\n",
            "        Mother Name    Class  Section  Class-Section             Teacher  \n",
            "0        Renee Sood  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "1      Advik Mammen  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "2  Vaibhav Bhargava  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "3          Sara Rau  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "4     Nirvi Shankar  Class 1        A      Class 1-A  T.Sri Venkateshwar  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:28:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data with Predictions:\n",
            "  Student ID        Student Name Student ID.1  Attendance (%)  Internal Marks  \\\n",
            "0       S001       Himmat Sehgal         S001           56.22              16   \n",
            "1       S002      Reyansh Tailor         S002           96.55              26   \n",
            "2       S003           Tanya Ben         S003           81.24              29   \n",
            "3       S004        Yasmin Reddy         S004           71.91              38   \n",
            "4       S005  Dharmajan Dhaliwal         S005           40.92              13   \n",
            "\n",
            "   External Marks  Total Marks Grade  Gender  Age  ... Guardian Contact  \\\n",
            "0              51           67     B    Male   12  ...       9014475712   \n",
            "1              25           51     C  Female   11  ...       9592551615   \n",
            "2              51           80     B    Male   12  ...       9021637593   \n",
            "3              23           61     B  Female   11  ...       9486986073   \n",
            "4              30           43     C  Female   10  ...       9262754377   \n",
            "\n",
            "  Preferred Mode           Father Name       Mother Name    Class  Section  \\\n",
            "0       WhatsApp          Akarsh Borra        Renee Sood  Class 1        A   \n",
            "1            SMS             Baiju Din      Advik Mammen  Class 1        A   \n",
            "2            SMS            Rania Seth  Vaibhav Bhargava  Class 1        A   \n",
            "3            SMS    Pranay Subramanian          Sara Rau  Class 1        A   \n",
            "4            SMS  Uthkarsh Chakraborty     Nirvi Shankar  Class 1        A   \n",
            "\n",
            "  Class-Section             Teacher  Predicted_Risk Predicted_Probability  \n",
            "0     Class 1-A  T.Sri Venkateshwar               1              0.991092  \n",
            "1     Class 1-A  T.Sri Venkateshwar               0              0.002315  \n",
            "2     Class 1-A  T.Sri Venkateshwar               0              0.002315  \n",
            "3     Class 1-A  T.Sri Venkateshwar               0              0.002315  \n",
            "4     Class 1-A  T.Sri Venkateshwar               1              0.991092  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    }
  ]
}